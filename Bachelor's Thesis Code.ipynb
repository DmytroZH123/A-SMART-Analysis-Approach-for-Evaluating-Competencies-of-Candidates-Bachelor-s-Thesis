{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYj7Gn2YbR78"
      },
      "source": [
        "# Developing Algorithms for Evaluating Competencies of Candidates for IT Positions: A SMART Analysis Approach - Bachelor's Thesis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9k6LN9LbR7-"
      },
      "source": [
        "Today, entrepreneurship emphasizes the use of the latest technologies and analytical tools for effective human resource management. It is vital to employ objective, accurate, and efficient methods to assess candidate skills,ensuring high quality staffing and competitiveness. Implementing a modern approach of SMART analysis can significantly enhance the candidate selection process and human resource management. This ensure that candidates’ skills align with the needs of the IT industry, contributing to the further sector’s development overall. In my Bachelor’s Diploma Thesis, I investigated the general recruitment process, where pre-planning of the recruitment process to assess candidates’ skills is the first stage and one of the key aspects of effective candidate selection. The second stage involves obtaining a large array of data, such as resumes, containing essential information about each candidate’s skills, education, work experience, achievements, etc. The third stage is the selection stage itself: this involves drawing up a short list of a few applicants for a vacant position from the initial large pool of candidates.  \n",
        "\n",
        "To solve the problem of selecting the ideal candidate, I proved the need to implement an automated system for assessing skills precisely at the third stage, where the system can provide the most effective evaluation of candidate skills. I proposed an automated solution consisting of three stages:  \n",
        "1) Parsing information from candidates’ resumes using parsers, specifically with libraries like PyPDF, re, and NLTK;\n",
        "2) Converting the extracted information into vectors using SMART analysis methods, such as Bag-of-words, TF-IDF, Word2Vec, GloVe, and fasttext. This stage also involves summarizing knowledge about words and considering their contexts in the text using models like ELMo and BERT;\n",
        "3) Comparing vectors of resume corpora and job descriptions to assess the candidate’s skills, experience and qualifications against the company’s requirements using similarity measures like Jaccard, Dice, cosine, sqrt-cos,\n",
        "and ISC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7m4NtN6FbR7_"
      },
      "source": [
        "### Section 1: Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhcqlYgRbR7_"
      },
      "outputs": [],
      "source": [
        "# Import all necessary libraries\n",
        "import re\n",
        "import nltk\n",
        "import torch\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from pypdf import PdfReader\n",
        "from itertools import product\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from scipy import stats\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from gensim.models import KeyedVectors\n",
        "from transformers import BertTokenizer, BertModel\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ReksOTPWbR8A",
        "outputId": "9280baa0-7025-44c3-f7e6-bdc377e021e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\dmytro.zhuk_whalebon\\AppData\\Roaming\\nltk_dat\n",
            "[nltk_data]     a...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\dmytro.zhuk_whalebon\\AppData\\Roaming\\nltk_dat\n",
            "[nltk_data]     a...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\dmytro.zhuk_whalebon\\AppData\\Roaming\\nltk_dat\n",
            "[nltk_data]     a...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\dmytro.zhuk_whalebon\\AppData\\Roaming\\nltk_dat\n",
            "[nltk_data]     a...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download all necessary sets of words\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MhLjSVxhbR8A"
      },
      "outputs": [],
      "source": [
        "# Text preprocessing functions\n",
        "\n",
        "# Read resume\n",
        "def read_resume(resume) -> str:\n",
        "    try:\n",
        "        reader = PdfReader(resume)\n",
        "        number_of_pages = reader.get_num_pages()\n",
        "        text = ''\n",
        "        for page_number in range(number_of_pages):\n",
        "            page = reader.get_page(page_number)\n",
        "            page_content = page.extract_text()\n",
        "            text+=page_content\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f'The resume {resume} was not scraped due to {e}.'\n",
        "\n",
        "# Read position description\n",
        "def read_position(position) -> str:\n",
        "    try:\n",
        "        with open(position) as file:\n",
        "            return file.read()\n",
        "    except Exception as e:\n",
        "        return f'The position {position} was not scraped due to {e}.'\n",
        "\n",
        "# Tokenize description\n",
        "def tokenize_description(description) -> list:\n",
        "    try:\n",
        "        return nltk.sent_tokenize(description)\n",
        "    except Exception as e:\n",
        "        return f'The description {description} was not scraped due to {e}.'\n",
        "\n",
        "# Lemmatization; stopwords, punctuation, and whitespace removal\n",
        "def preprocessing_text(text) -> str:\n",
        "    try:\n",
        "        lemmatizer = WordNetLemmatizer()\n",
        "        text = text.split()\n",
        "        text = [lemmatizer.lemmatize(word) for word in text if not word in set(stopwords.words('english'))]\n",
        "        text = ' '.join(text)\n",
        "        text = re.sub(r'\\d+', '', text)\n",
        "        text = re.sub(r'[^\\w\\s]', '', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = text.lower().strip()\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        return f'The text was not preprocessed due to {e}.'\n",
        "\n",
        "# Create one corpus from smaller corpuses\n",
        "def create_corpus(text) -> str:\n",
        "    try:\n",
        "        return ' '.join(text)\n",
        "    except Exception as e:\n",
        "        return f'The corpus was not created due to {e}.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPKPQMXVbR8B"
      },
      "outputs": [],
      "source": [
        "# Metrics and helping functions\n",
        "\n",
        "# Cosine similarity - Euclidean distance\n",
        "def cos_sim(a, b):\n",
        "    try:\n",
        "        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
        "    except Exception as e:\n",
        "        return f'The cosine similarity was not calculated due to {e}.'\n",
        "\n",
        "# Sqrt-cos similarity - Hellinger distance -> needs to be normalized on the scale from 0 to 1 due to non-support of negative values\n",
        "def sqrt_cos_sim(a, b):\n",
        "    try:\n",
        "        def hellinger_distance(a,b):\n",
        "            return np.sqrt(np.sum((np.sqrt(a) - np.sqrt(b))**2)) / np.sqrt(2)\n",
        "        return np.sqrt(1 - hellinger_distance(a,b)**2)\n",
        "    except Exception as e:\n",
        "        return f'Sqrt-cos similarity was not calculated due to {e}.'\n",
        "\n",
        "# MinMax scaler\n",
        "def normalize_vector(vector):\n",
        "    try:\n",
        "        return (vector - np.min(vector)) / (np.max(vector) - np.min(vector))\n",
        "    except Exception as e:\n",
        "        return f'Vector normalization was not calculated due to {e}.'\n",
        "\n",
        "# Improved sqrt-cos similarity - Manhattan distance\n",
        "def improved_sqrt_cos_sim(a, b):\n",
        "    try:\n",
        "        return np.sqrt(np.dot(a,b)) / (np.sqrt(np.linalg.norm(a)) * np.sqrt(np.linalg.norm(b)))\n",
        "    except Exception as e:\n",
        "        return f'Improved sqrt-cos similarity was not calculated due to {e}.'\n",
        "\n",
        "# Jaccard similarity\n",
        "def jaccard_sim(a, b):\n",
        "    try:\n",
        "        set1 = set(a)\n",
        "        set2 = set(b)\n",
        "        intersection = len(set1.intersection(set2))\n",
        "        union = len(set1.union(set2))\n",
        "        similarity = intersection / union\n",
        "        return similarity\n",
        "    except Exception as e:\n",
        "        return f'Jaccard similarity was not calculated due to {e}.'\n",
        "\n",
        "# Dice similarity\n",
        "def dice_sim(a, b):\n",
        "    try:\n",
        "        set1 = set(a)\n",
        "        set2 = set(b)\n",
        "        intersection = len(set1.intersection(set2))\n",
        "        dice = (2.0 * intersection) / (len(set1) + len(set2))\n",
        "        return dice\n",
        "    except Exception as e:\n",
        "        return f'Dice similarity was not calculated due to {e}.'\n",
        "\n",
        "# Cosine similarity for tensors - Euclidean distance\n",
        "def cosine_similarity_tensorflow(a, b):\n",
        "    try:\n",
        "        a = tf.reshape(a, [-1])\n",
        "        b = tf.reshape(b, [-1])\n",
        "        dot_product = tf.reduce_sum(a * b)\n",
        "        magnitude1 = tf.sqrt(tf.reduce_sum(a * a))\n",
        "        magnitude2 = tf.sqrt(tf.reduce_sum(b * b))\n",
        "        similarity = dot_product / (magnitude1 * magnitude2)\n",
        "        return similarity\n",
        "    except Exception as e:\n",
        "        return f'The cosine similarity was not calculated due to {e}.'\n",
        "\n",
        "# Sqrt-cos similarity for tensors - Hellinger distance -> needs to be normalized on the scale from 0 to 1 due to non-support of negative values\n",
        "def sqrt_cos_sim_tensorflow(a, b):\n",
        "    try:\n",
        "        a = tf.clip_by_value(a, 0.0, 1.0)\n",
        "        b = tf.clip_by_value(b, 0.0, 1.0)\n",
        "        def hellinger_distance(a, b):\n",
        "            return tf.sqrt(tf.reduce_sum(tf.square(tf.sqrt(a) - tf.sqrt(b)))) / tf.sqrt(2.0)\n",
        "        similarity = tf.sqrt(1 - tf.square(hellinger_distance(a, b)))\n",
        "        return similarity\n",
        "    except Exception as e:\n",
        "        return f'Sqrt-cos similarity was not calculated due to {e}.'\n",
        "\n",
        "# Improved sqrt-cos similarity for tensors - Manhattan distance\n",
        "def improved_sqrt_cos_sim_tensorflow(a, b):\n",
        "    try:\n",
        "        a = tf.reshape(a, [-1])\n",
        "        b = tf.reshape(b, [-1])\n",
        "        dot_product = tf.sqrt(tf.reduce_sum(tf.multiply(a, b)))\n",
        "        magnitude1 = tf.sqrt(tf.norm(a))\n",
        "        magnitude2 = tf.sqrt(tf.norm(b))\n",
        "        similarity = dot_product / (magnitude1 * magnitude2)\n",
        "        return similarity\n",
        "    except Exception as e:\n",
        "        return f'Improved sqrt-cos similarity was not calculated due to {e}.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWHnCb08bR8B"
      },
      "outputs": [],
      "source": [
        "# Models word embeddings functions\n",
        "\n",
        "# Bag-of-words model\n",
        "def bag_of_words(resume_corpus, position_corpus) -> list:\n",
        "    try:\n",
        "        resume_tokens = word_tokenize(resume_corpus)\n",
        "        position_tokens = word_tokenize(position_corpus)\n",
        "        vocabulary = set(resume_tokens + position_tokens)\n",
        "        vectorizer = CountVectorizer(vocabulary=vocabulary)\n",
        "        vectorizer.fit([resume_corpus, position_corpus])\n",
        "        resume_bow = vectorizer.transform([resume_corpus])\n",
        "        position_bow = vectorizer.transform([position_corpus])\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        df = pd.DataFrame(\n",
        "            data=[resume_bow[0].toarray()[0], position_bow[0].toarray()[0]],\n",
        "            columns=feature_names,\n",
        "            index=[resume_corpus, position_corpus])\n",
        "        return [df, resume_bow[0].toarray()[0], position_bow[0].toarray()[0]]\n",
        "    except Exception as e:\n",
        "        return f'Bag-of-words model was not created due to {e}.'\n",
        "\n",
        "# TF-IDF model\n",
        "def tf_idf(resume_corpus, position_corpus) -> list:\n",
        "    try:\n",
        "        resume_tokens = word_tokenize(resume_corpus)\n",
        "        position_tokens = word_tokenize(position_corpus)\n",
        "        vocabulary = set(resume_tokens + position_tokens)\n",
        "        vectorizer = TfidfVectorizer(vocabulary=vocabulary)\n",
        "        vectorizer.fit([resume_corpus, position_corpus])\n",
        "        resume_bow = vectorizer.transform([resume_corpus])\n",
        "        position_bow = vectorizer.transform([position_corpus])\n",
        "        feature_names = vectorizer.get_feature_names_out()\n",
        "        df = pd.DataFrame(\n",
        "            data=[resume_bow[0].toarray()[0], position_bow[0].toarray()[0]],\n",
        "            columns=feature_names,\n",
        "            index=[resume_corpus, position_corpus])\n",
        "        return [df, resume_bow[0].toarray()[0], position_bow[0].toarray()[0]]\n",
        "    except Exception as e:\n",
        "        return f'Tf-idf model was not created due to {e}.'\n",
        "\n",
        "# Word2Vec, GloVe, and fasttext build model\n",
        "def build_model_ncontext(model_path) -> KeyedVectors:\n",
        "    try:\n",
        "        return KeyedVectors.load(model_path)\n",
        "    except Exception as e:\n",
        "        return f'The model {model_path} was not built due to {e}.'\n",
        "\n",
        "# Word2Vec, GloVe, and fasttext word embeddings\n",
        "def ncontext_word_embeddings(resume_tokens, position_tokens, model, vectors_size) -> list:\n",
        "    try:\n",
        "        p_sen1 = [item for sublist in resume_tokens for item in sublist]\n",
        "        p_sen2 = [item for sublist in position_tokens for item in sublist]\n",
        "        sen_vec1 = np.zeros(vectors_size)\n",
        "        sen_vec2 = np.zeros(vectors_size)\n",
        "        for val in p_sen1:\n",
        "            try:\n",
        "                sen_vec1 = np.add(sen_vec1, model[val])\n",
        "            except:\n",
        "                sen_vec1 = np.add(sen_vec1, 0)\n",
        "                continue\n",
        "        for val in p_sen2:\n",
        "            try:\n",
        "                sen_vec2 = np.add(sen_vec2, model[val])\n",
        "            except:\n",
        "                sen_vec2 = np.add(sen_vec2, 0)\n",
        "                continue\n",
        "        return [sen_vec1, sen_vec2]\n",
        "    except Exception as e:\n",
        "        return f'Word embeddings were not obtained by model {model} due to {e}.'\n",
        "\n",
        "# Build BERT model and obtain word embeddings\n",
        "def context_word_embeddings_bert(model_name, resume_corpus, position_corpus, tokenizer, model) -> list:\n",
        "    try:\n",
        "        return [get_word_embeddings(resume_corpus, tokenizer, model), get_word_embeddings(position_corpus, tokenizer, model)]\n",
        "    except Exception as e:\n",
        "        return f'Word embeddings were not obtained by BERT model due to {e}.'\n",
        "\n",
        "# Helping function to obtain word embeddings from BERT model\n",
        "def get_word_embeddings(sentence, tokenizer, model):\n",
        "    try:\n",
        "        tokens = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**tokens)\n",
        "        hidden_states = outputs.hidden_states\n",
        "        embeddings = hidden_states[-1].squeeze(0)  # Embeddings from last layer\n",
        "        if embeddings.size(0) > 100:\n",
        "            embeddings = embeddings[:100, :]\n",
        "        return embeddings\n",
        "    except Exception as e:\n",
        "        return f'Word embeddings were not obtained by BERT model due to {e}.'\n",
        "\n",
        "# Build ElMo model and obtain word embeddings\n",
        "def context_word_embeddings_elmo(elmo_model, resume_corpus, position_corpus):\n",
        "    try:\n",
        "        return elmo_model.signatures[\"default\"](tf.constant([resume_corpus, position_corpus]))[\"elmo\"]\n",
        "    except Exception as e:\n",
        "        return f'Word embeddings were not obtained by ElMo model due to {e}.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Pb6YVMhbR8B"
      },
      "outputs": [],
      "source": [
        "# Read resume and position descriptions\n",
        "resume = read_resume(\"Business analyst Male.pdf\")\n",
        "position = read_position(\"Business Analyst.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8im0SeIbR8C",
        "outputId": "5e3fa9c9-5a7e-442c-a4ad-935e7e17bb3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page 1 of 2 Abc Abc  \n",
            "E-mail  : 111.abc@gmail.com\n",
            "Position : BUSINESS ANALYST /SYSTEM ANALYST \n",
            "SUMMARY \n",
            "I’d like to suggest to you my expertise , knowle dge and skills . My skills \n",
            "of instant response to change s in the cases, proficiency of \n",
            "negotiations , mediat ion, issue s solving allow me be sure in my ability \n",
            "to quickly dive into a new sphere of activity  \n",
            "EDUCATION \n",
            "Years Educational institution  Qualification  \n",
            "1989-1994 Yaroslav Mudryi National Law University  LL.M.\n",
            "PROFESSIONAL SKILLS  \n",
            "OS Windows, Android, iOS , MacOS, Ubuntu  \n",
            "Technologies  WEB, mobile  \n",
            "DBMS  MS SQL, MySQL, Oracle, Access  (surface immersion ) \n",
            "BA support tools  Jira, Confluence, ClickU p, MS project, Google Docs, Enterprise architect , \n",
            "MS Office etc. , Postman  \n",
            "Design , diagrams  AdobeXD, inVision, Figma, Draw.io, Miro, \n",
            "Methodologies  Agile (Scrum, Kanban), Waterfall  \n",
            "Foreign languages  English Upper Intermediate  \n",
            "Other skills  IDEF, UML, BPMN , REST API, GraphQL , XML, JSON  \n",
            "SERVICE RECORDS  \n",
            "Years  Employer  Position and brief job description  \n",
            "01/2021  Telesens  Business analyst  \n",
            "06/2020 -12/2020  DiPocket  Business analyst  \n",
            "08/2018 -05/2020  Resty application  Business analyst, Product manager  \n",
            "PROJECT EXPERIENCE  \n",
            "Years  Brief project \n",
            "description  Your role(s) and responsibilities  \n",
            "2021-2022 Antifraud Services  \n",
            "(detecti ng of \n",
            "elements of \n",
            "subscriber fraudulent \n",
            "activity ) Requirement's analysis.  Integration  solution . Tech \n",
            "requirements specifications. Use case scenarios.  UML \n",
            "sequence d iagrams . \n",
            "2021-2022 Omnichannel \n",
            "orchestration of \n",
            "subscriber activities  Requirement's analysis.  Integration  solution . Tech \n",
            "requirements specifications. Use case scenarios.  UML \n",
            "sequence d iagrams . \n",
            "2021-2022 RBT Integration  \n",
            "solution . Requirement's analysis.  Tech requirements specifications. \n",
            "Use case scenarios.  UML sequence d iagrams .  \n",
            "2021 App development \n",
            "cost calculator  Requirement's analysis. Product requirements, \n",
            "business/tech requirements specifications. Use case \n",
            "scenarios.  \n",
            "2021 Fitness project  Tech requirements specifications.  Telesens_CV_Template(1) (2)  \n",
            "Page 2 of 2 2020 Social net. Value – \n",
            "communication \n",
            "between user through \n",
            "exchanging of video \n",
            "questions and \n",
            "responds.  Requirement's analysis. Product requirements, \n",
            "business/tech requirements specifications. Use case \n",
            "scenarios.  \n",
            "2019-2020 Legal -tech project. \n",
            "Value – \n",
            "automati zation of \n",
            "communication \n",
            "between courts \n",
            "administration and \n",
            "participants of trials.  Market researching. Target definition. Analysis of \n",
            "customer’s business needs. Product roadmapping. Analysis \n",
            "sales pipeline. Customer development. Requirement's \n",
            "analysis. Requ irements elicitation, Perform requirements \n",
            "management, prioritization, traceability, verification, and \n",
            "validation of the requirements. Negotiations with clients \n",
            "and partners for product facilitation. Product requirements, \n",
            "business/tech requirements specifi cations. Risk \n",
            "management and troubleshooting.  \n",
            "2018-2019 Health -care project. \n",
            "Value – optimization \n",
            "and automatization of \n",
            "functioning of the \n",
            "ambulance service.  Analysis of customer’s business needs. Requirement's \n",
            "analysis. Requirements elicitation, Taking a part in a \n",
            "performing requirements management, prioritization, \n",
            "traceability, verification, and validation of the \n",
            "requirements. Negotiations with clients and partners for \n",
            "product facilitation. Business requirements specifications. \n",
            "Use case scenarios.  \n",
            "CERTIFICATIONS/TRAINING:  \n",
            "Theory and practice of mediation – course of mediation and conflictology  \n",
            "Productman – practice course of IT product management  \n",
            "IAMBA – practice course of IT business analysis  \n",
            "Supreme BA – advanced practice course of IT business analysis  \n",
            "TECHMIND – course of basic technical knowledge for IT managers  \n",
            "IAM SCRUM – practice course of Scrum Techmind – practice course of IT technical skills for managers  \n"
          ]
        }
      ],
      "source": [
        "print(resume)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7P02dsPWbR8C",
        "outputId": "6ddcc530-4d54-4807-c8a3-8aad334ca2d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "https://www.amazon.jobs/en/jobs/2608538/business-analyst\n",
            "\n",
            "DESCRIPTION\n",
            "Will you be able to determine if Amazon's Middle Mile automated driver supply planning is predicting the 'right' number of driver shifts to deliver millions of packages every day to its customers? As a Business Analyst, you will operate at the crossroads of multiple complex Amazon systems, getting global visibility of how Amazon moves inventory across our network and serves our customers. You will work with the core optimization models that drive the Middle Mile planning business for Amazon. You will enable the creation of products that drive ever-greater automation, scalability and optimization of every aspect of transportation, removing cost and delivering speed of execution for our customers. The impact of your work will be global, material, and remarkable. The successful candidate will be voraciously curious about Amazonâ€™s transportation operations and how data consumed and produced by our systems can be used to improve outcomes and lower costs. Your responsibility is to expose and measure the current performance of our systems, find and quantify opportunities for improvement, and dive deep into existing algorithms to explain unexpected performance. We are looking for a sophisticated user of data querying tools and an expert at synthesizing / communicating insights & recommendations to audiences of varying levels of technical sophistication.\n",
            "\n",
            "The Middle Mile Transportation Technology organization builds complex software solutions that work across our vendors, warehouses, and carriers to optimize both time & cost of getting the packages delivered. Our services already handle thousands of requests per second, make business decisions impacting billions of dollars a year, integrate with a network of small and large carriers, owner-operators, and drivers worldwide, manage business rules for millions of unique products, and improve ordering and delivery experience for millions of online shoppers. That said, this remains a fast growing business and our technical journey has only started. Our mission is to build the most efficient and optimal transportation solution on the planet, using our technology and engineering muscle as our biggest advantage. We aim to leverage cutting edge technologies in big data, machine learning, and optimization techniques, and operate high volume, low latency, and high availability services.\n",
            "\n",
            "As a member of this collaborative team, you will have an opportunity to make an impact in Amazon Logistics and work with a group of talented program managers, product managers, research scientists, software developers, and business stakeholders to design the Amazon network of the future.\n",
            "\n",
            "Key job responsibilities\n",
            "- Perform complex data research to identify opportunities to reduce fulfillment costs as well as improve efficiencies and customer experience in supporting business decision making\n",
            "- Design, develop, and establish KPIs to provide strategic insights to drive growth and performance\n",
            "- Systematically identify data source / forecast error and follow through on the resolutions to ensure that future plans are updated with improved business processes\n",
            "- Develop standardized metrics to evaluate and benchmark pertaining to short and long term network planning and forecasting\n",
            "- Pull and report data from numerous databases (using Excel, SQL, and/or other data management systems) and proven capability to dive deep and utilize known research and problem solving techniques\n",
            "- Communicate complex insights to stakeholders, both verbally and in writing\n",
            "\n",
            "We are open to hiring candidates to work out of one of the following locations:\n",
            "\n",
            "Luxembourg, LUX\n",
            "\n",
            "BASIC QUALIFICATIONS\n",
            "- Bachelor's degree or equivalent\n",
            "- Experience in Excel (including VBA, pivot tables, array functions, power pivots, etc.) and data visualization tools such as Tableau\n",
            "- Experience in business or financial analysis\n",
            "- Experience defining requirements and using data and metrics to draw business insights\n",
            "- Experience with Excel\n",
            "- Experience with SQL\n",
            "\n",
            "PREFERRED QUALIFICATIONS\n",
            "- Experience with other languages like Tableau, python or R\n",
            "- Experience making business recommendations and influencing stakeholders\n"
          ]
        }
      ],
      "source": [
        "print(position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDXmper2bR8C"
      },
      "outputs": [],
      "source": [
        "# Tokenize descriptions into list of sentences\n",
        "resume = tokenize_description(resume)\n",
        "position = tokenize_description(position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djVse5MobR8C",
        "outputId": "f0da5a61-2f4f-4f2c-9b72-10be75a822b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Page 1 of 2 Abc Abc  \\nE-mail  : 111.abc@gmail.com\\nPosition : BUSINESS ANALYST /SYSTEM ANALYST \\nSUMMARY \\nI’d like to suggest to you my expertise , knowle dge and skills .',\n",
              " 'My skills \\nof instant response to change s in the cases, proficiency of \\nnegotiations , mediat ion, issue s solving allow me be sure in my ability \\nto quickly dive into a new sphere of activity  \\nEDUCATION \\nYears Educational institution  Qualification  \\n1989-1994 Yaroslav Mudryi National Law University  LL.M.',\n",
              " 'PROFESSIONAL SKILLS  \\nOS Windows, Android, iOS , MacOS, Ubuntu  \\nTechnologies  WEB, mobile  \\nDBMS  MS SQL, MySQL, Oracle, Access  (surface immersion ) \\nBA support tools  Jira, Confluence, ClickU p, MS project, Google Docs, Enterprise architect , \\nMS Office etc.',\n",
              " \", Postman  \\nDesign , diagrams  AdobeXD, inVision, Figma, Draw.io, Miro, \\nMethodologies  Agile (Scrum, Kanban), Waterfall  \\nForeign languages  English Upper Intermediate  \\nOther skills  IDEF, UML, BPMN , REST API, GraphQL , XML, JSON  \\nSERVICE RECORDS  \\nYears  Employer  Position and brief job description  \\n01/2021  Telesens  Business analyst  \\n06/2020 -12/2020  DiPocket  Business analyst  \\n08/2018 -05/2020  Resty application  Business analyst, Product manager  \\nPROJECT EXPERIENCE  \\nYears  Brief project \\ndescription  Your role(s) and responsibilities  \\n2021-2022 Antifraud Services  \\n(detecti ng of \\nelements of \\nsubscriber fraudulent \\nactivity ) Requirement's analysis.\",\n",
              " 'Integration  solution .',\n",
              " 'Tech \\nrequirements specifications.',\n",
              " 'Use case scenarios.',\n",
              " 'UML \\nsequence d iagrams .',\n",
              " \"2021-2022 Omnichannel \\norchestration of \\nsubscriber activities  Requirement's analysis.\",\n",
              " 'Integration  solution .',\n",
              " 'Tech \\nrequirements specifications.',\n",
              " 'Use case scenarios.',\n",
              " 'UML \\nsequence d iagrams .',\n",
              " '2021-2022 RBT Integration  \\nsolution .',\n",
              " \"Requirement's analysis.\",\n",
              " 'Tech requirements specifications.',\n",
              " 'Use case scenarios.',\n",
              " 'UML sequence d iagrams .',\n",
              " \"2021 App development \\ncost calculator  Requirement's analysis.\",\n",
              " 'Product requirements, \\nbusiness/tech requirements specifications.',\n",
              " 'Use case \\nscenarios.',\n",
              " '2021 Fitness project  Tech requirements specifications.',\n",
              " 'Telesens_CV_Template(1) (2)  \\nPage 2 of 2 2020 Social net.',\n",
              " 'Value – \\ncommunication \\nbetween user through \\nexchanging of video \\nquestions and \\nresponds.',\n",
              " \"Requirement's analysis.\",\n",
              " 'Product requirements, \\nbusiness/tech requirements specifications.',\n",
              " 'Use case \\nscenarios.',\n",
              " '2019-2020 Legal -tech project.',\n",
              " 'Value – \\nautomati zation of \\ncommunication \\nbetween courts \\nadministration and \\nparticipants of trials.',\n",
              " 'Market researching.',\n",
              " 'Target definition.',\n",
              " 'Analysis of \\ncustomer’s business needs.',\n",
              " 'Product roadmapping.',\n",
              " 'Analysis \\nsales pipeline.',\n",
              " 'Customer development.',\n",
              " \"Requirement's \\nanalysis.\",\n",
              " 'Requ irements elicitation, Perform requirements \\nmanagement, prioritization, traceability, verification, and \\nvalidation of the requirements.',\n",
              " 'Negotiations with clients \\nand partners for product facilitation.',\n",
              " 'Product requirements, \\nbusiness/tech requirements specifi cations.',\n",
              " 'Risk \\nmanagement and troubleshooting.',\n",
              " '2018-2019 Health -care project.',\n",
              " 'Value – optimization \\nand automatization of \\nfunctioning of the \\nambulance service.',\n",
              " 'Analysis of customer’s business needs.',\n",
              " \"Requirement's \\nanalysis.\",\n",
              " 'Requirements elicitation, Taking a part in a \\nperforming requirements management, prioritization, \\ntraceability, verification, and validation of the \\nrequirements.',\n",
              " 'Negotiations with clients and partners for \\nproduct facilitation.',\n",
              " 'Business requirements specifications.',\n",
              " 'Use case scenarios.',\n",
              " 'CERTIFICATIONS/TRAINING:  \\nTheory and practice of mediation – course of mediation and conflictology  \\nProductman – practice course of IT product management  \\nIAMBA – practice course of IT business analysis  \\nSupreme BA – advanced practice course of IT business analysis  \\nTECHMIND – course of basic technical knowledge for IT managers  \\nIAM SCRUM – practice course of Scrum Techmind – practice course of IT technical skills for managers']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fetf8oucbR8D",
        "outputId": "c2fc9c38-35cb-4ee3-bfb3-dc4155efc66f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[\"https://www.amazon.jobs/en/jobs/2608538/business-analyst\\n\\nDESCRIPTION\\nWill you be able to determine if Amazon's Middle Mile automated driver supply planning is predicting the 'right' number of driver shifts to deliver millions of packages every day to its customers?\",\n",
              " 'As a Business Analyst, you will operate at the crossroads of multiple complex Amazon systems, getting global visibility of how Amazon moves inventory across our network and serves our customers.',\n",
              " 'You will work with the core optimization models that drive the Middle Mile planning business for Amazon.',\n",
              " 'You will enable the creation of products that drive ever-greater automation, scalability and optimization of every aspect of transportation, removing cost and delivering speed of execution for our customers.',\n",
              " 'The impact of your work will be global, material, and remarkable.',\n",
              " 'The successful candidate will be voraciously curious about Amazonâ€™s transportation operations and how data consumed and produced by our systems can be used to improve outcomes and lower costs.',\n",
              " 'Your responsibility is to expose and measure the current performance of our systems, find and quantify opportunities for improvement, and dive deep into existing algorithms to explain unexpected performance.',\n",
              " 'We are looking for a sophisticated user of data querying tools and an expert at synthesizing / communicating insights & recommendations to audiences of varying levels of technical sophistication.',\n",
              " 'The Middle Mile Transportation Technology organization builds complex software solutions that work across our vendors, warehouses, and carriers to optimize both time & cost of getting the packages delivered.',\n",
              " 'Our services already handle thousands of requests per second, make business decisions impacting billions of dollars a year, integrate with a network of small and large carriers, owner-operators, and drivers worldwide, manage business rules for millions of unique products, and improve ordering and delivery experience for millions of online shoppers.',\n",
              " 'That said, this remains a fast growing business and our technical journey has only started.',\n",
              " 'Our mission is to build the most efficient and optimal transportation solution on the planet, using our technology and engineering muscle as our biggest advantage.',\n",
              " 'We aim to leverage cutting edge technologies in big data, machine learning, and optimization techniques, and operate high volume, low latency, and high availability services.',\n",
              " 'As a member of this collaborative team, you will have an opportunity to make an impact in Amazon Logistics and work with a group of talented program managers, product managers, research scientists, software developers, and business stakeholders to design the Amazon network of the future.',\n",
              " \"Key job responsibilities\\n- Perform complex data research to identify opportunities to reduce fulfillment costs as well as improve efficiencies and customer experience in supporting business decision making\\n- Design, develop, and establish KPIs to provide strategic insights to drive growth and performance\\n- Systematically identify data source / forecast error and follow through on the resolutions to ensure that future plans are updated with improved business processes\\n- Develop standardized metrics to evaluate and benchmark pertaining to short and long term network planning and forecasting\\n- Pull and report data from numerous databases (using Excel, SQL, and/or other data management systems) and proven capability to dive deep and utilize known research and problem solving techniques\\n- Communicate complex insights to stakeholders, both verbally and in writing\\n\\nWe are open to hiring candidates to work out of one of the following locations:\\n\\nLuxembourg, LUX\\n\\nBASIC QUALIFICATIONS\\n- Bachelor's degree or equivalent\\n- Experience in Excel (including VBA, pivot tables, array functions, power pivots, etc.)\",\n",
              " 'and data visualization tools such as Tableau\\n- Experience in business or financial analysis\\n- Experience defining requirements and using data and metrics to draw business insights\\n- Experience with Excel\\n- Experience with SQL\\n\\nPREFERRED QUALIFICATIONS\\n- Experience with other languages like Tableau, python or R\\n- Experience making business recommendations and influencing stakeholders']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpaX35mubR8D"
      },
      "outputs": [],
      "source": [
        "# Preprocess sentences in descriptions\n",
        "resume = [preprocessing_text(sentence) for sentence in resume]\n",
        "position = [preprocessing_text(sentence) for sentence in position]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nLLpCLXmbR8D",
        "outputId": "5c63072c-dbc5-4516-b1b3-536cfdb157e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['page abc abc email abcgmailcom position business analyst system analyst summary id like suggest expertise knowle dge skill',\n",
              " 'my skill instant response change cases proficiency negotiation mediat ion issue solving allow sure ability quickly dive new sphere activity education years educational institution qualification yaroslav mudryi national law university llm',\n",
              " 'professional skills os windows android ios macos ubuntu technologies web mobile dbms ms sql mysql oracle access surface immersion ba support tool jira confluence clicku p ms project google docs enterprise architect ms office etc',\n",
              " 'postman design diagram adobexd invision figma drawio miro methodologies agile scrum kanban waterfall foreign language english upper intermediate other skill idef uml bpmn rest api graphql xml json service records years employer position brief job description telesens business analyst dipocket business analyst resty application business analyst product manager project experience years brief project description your roles responsibility antifraud services detecti ng element subscriber fraudulent activity requirements analysis',\n",
              " 'integration solution',\n",
              " 'tech requirement specifications',\n",
              " 'use case scenarios',\n",
              " 'uml sequence iagrams',\n",
              " 'omnichannel orchestration subscriber activity requirements analysis',\n",
              " 'integration solution',\n",
              " 'tech requirement specifications',\n",
              " 'use case scenarios',\n",
              " 'uml sequence iagrams',\n",
              " 'rbt integration solution',\n",
              " 'requirements analysis',\n",
              " 'tech requirement specifications',\n",
              " 'use case scenarios',\n",
              " 'uml sequence iagrams',\n",
              " 'app development cost calculator requirements analysis',\n",
              " 'product requirements businesstech requirement specifications',\n",
              " 'use case scenarios',\n",
              " 'fitness project tech requirement specifications',\n",
              " 'telesens_cv_template page social net',\n",
              " 'value communication user exchanging video question responds',\n",
              " 'requirements analysis',\n",
              " 'product requirements businesstech requirement specifications',\n",
              " 'use case scenarios',\n",
              " 'legal tech project',\n",
              " 'value automati zation communication court administration participant trials',\n",
              " 'market researching',\n",
              " 'target definition',\n",
              " 'analysis customers business needs',\n",
              " 'product roadmapping',\n",
              " 'analysis sale pipeline',\n",
              " 'customer development',\n",
              " 'requirements analysis',\n",
              " 'requ irements elicitation perform requirement management prioritization traceability verification validation requirements',\n",
              " 'negotiations client partner product facilitation',\n",
              " 'product requirements businesstech requirement specifi cations',\n",
              " 'risk management troubleshooting',\n",
              " 'health care project',\n",
              " 'value optimization automatization functioning ambulance service',\n",
              " 'analysis customers business needs',\n",
              " 'requirements analysis',\n",
              " 'requirements elicitation taking part performing requirement management prioritization traceability verification validation requirements',\n",
              " 'negotiations client partner product facilitation',\n",
              " 'business requirement specifications',\n",
              " 'use case scenarios',\n",
              " 'certificationstraining theory practice mediation course mediation conflictology productman practice course it product management iamba practice course it business analysis supreme ba advanced practice course it business analysis techmind course basic technical knowledge it manager iam scrum practice course scrum techmind practice course it technical skill manager']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4TmXdImbR8D",
        "outputId": "1d6595b7-6c9c-41c6-b64a-656c62b430ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['httpswwwamazonjobsenjobsbusinessanalyst description will able determine amazons middle mile automated driver supply planning predicting right number driver shift deliver million package every day customers',\n",
              " 'as business analyst operate crossroad multiple complex amazon systems getting global visibility amazon move inventory across network serf customers',\n",
              " 'you work core optimization model drive middle mile planning business amazon',\n",
              " 'you enable creation product drive evergreater automation scalability optimization every aspect transportation removing cost delivering speed execution customers',\n",
              " 'the impact work global material remarkable',\n",
              " 'the successful candidate voraciously curious amazonâs transportation operation data consumed produced system used improve outcome lower costs',\n",
              " 'your responsibility expose measure current performance systems find quantify opportunity improvement dive deep existing algorithm explain unexpected performance',\n",
              " 'we looking sophisticated user data querying tool expert synthesizing communicating insight recommendation audience varying level technical sophistication',\n",
              " 'the middle mile transportation technology organization build complex software solution work across vendors warehouses carrier optimize time cost getting package delivered',\n",
              " 'our service already handle thousand request per second make business decision impacting billion dollar year integrate network small large carriers owneroperators driver worldwide manage business rule million unique products improve ordering delivery experience million online shoppers',\n",
              " 'that said remains fast growing business technical journey started',\n",
              " 'our mission build efficient optimal transportation solution planet using technology engineering muscle biggest advantage',\n",
              " 'we aim leverage cutting edge technology big data machine learning optimization techniques operate high volume low latency high availability services',\n",
              " 'as member collaborative team opportunity make impact amazon logistics work group talented program managers product managers research scientists software developers business stakeholder design amazon network future',\n",
              " 'key job responsibility perform complex data research identify opportunity reduce fulfillment cost well improve efficiency customer experience supporting business decision making design develop establish kpis provide strategic insight drive growth performance systematically identify data source forecast error follow resolution ensure future plan updated improved business process develop standardized metric evaluate benchmark pertaining short long term network planning forecasting pull report data numerous database using excel sql andor data management systems proven capability dive deep utilize known research problem solving technique communicate complex insight stakeholders verbally writing we open hiring candidate work one following locations luxembourg lux basic qualifications bachelors degree equivalent experience excel including vba pivot tables array functions power pivots etc',\n",
              " 'data visualization tool tableau experience business financial analysis experience defining requirement using data metric draw business insight experience excel experience sql preferred qualifications experience language like tableau python r experience making business recommendation influencing stakeholder']"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmUNX-zhbR8D",
        "outputId": "ad08f3fd-6260-400c-edfb-ea917a5b774e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['page',\n",
              "  'abc',\n",
              "  'abc',\n",
              "  'email',\n",
              "  'abcgmailcom',\n",
              "  'position',\n",
              "  'business',\n",
              "  'analyst',\n",
              "  'system',\n",
              "  'analyst',\n",
              "  'summary',\n",
              "  'id',\n",
              "  'like',\n",
              "  'suggest',\n",
              "  'expertise',\n",
              "  'knowle',\n",
              "  'dge',\n",
              "  'skill'],\n",
              " ['my',\n",
              "  'skill',\n",
              "  'instant',\n",
              "  'response',\n",
              "  'change',\n",
              "  'cases',\n",
              "  'proficiency',\n",
              "  'negotiation',\n",
              "  'mediat',\n",
              "  'ion',\n",
              "  'issue',\n",
              "  'solving',\n",
              "  'allow',\n",
              "  'sure',\n",
              "  'ability',\n",
              "  'quickly',\n",
              "  'dive',\n",
              "  'new',\n",
              "  'sphere',\n",
              "  'activity',\n",
              "  'education',\n",
              "  'years',\n",
              "  'educational',\n",
              "  'institution',\n",
              "  'qualification',\n",
              "  'yaroslav',\n",
              "  'mudryi',\n",
              "  'national',\n",
              "  'law',\n",
              "  'university',\n",
              "  'llm'],\n",
              " ['professional',\n",
              "  'skills',\n",
              "  'os',\n",
              "  'windows',\n",
              "  'android',\n",
              "  'ios',\n",
              "  'macos',\n",
              "  'ubuntu',\n",
              "  'technologies',\n",
              "  'web',\n",
              "  'mobile',\n",
              "  'dbms',\n",
              "  'ms',\n",
              "  'sql',\n",
              "  'mysql',\n",
              "  'oracle',\n",
              "  'access',\n",
              "  'surface',\n",
              "  'immersion',\n",
              "  'ba',\n",
              "  'support',\n",
              "  'tool',\n",
              "  'jira',\n",
              "  'confluence',\n",
              "  'clicku',\n",
              "  'p',\n",
              "  'ms',\n",
              "  'project',\n",
              "  'google',\n",
              "  'docs',\n",
              "  'enterprise',\n",
              "  'architect',\n",
              "  'ms',\n",
              "  'office',\n",
              "  'etc'],\n",
              " ['postman',\n",
              "  'design',\n",
              "  'diagram',\n",
              "  'adobexd',\n",
              "  'invision',\n",
              "  'figma',\n",
              "  'drawio',\n",
              "  'miro',\n",
              "  'methodologies',\n",
              "  'agile',\n",
              "  'scrum',\n",
              "  'kanban',\n",
              "  'waterfall',\n",
              "  'foreign',\n",
              "  'language',\n",
              "  'english',\n",
              "  'upper',\n",
              "  'intermediate',\n",
              "  'other',\n",
              "  'skill',\n",
              "  'idef',\n",
              "  'uml',\n",
              "  'bpmn',\n",
              "  'rest',\n",
              "  'api',\n",
              "  'graphql',\n",
              "  'xml',\n",
              "  'json',\n",
              "  'service',\n",
              "  'records',\n",
              "  'years',\n",
              "  'employer',\n",
              "  'position',\n",
              "  'brief',\n",
              "  'job',\n",
              "  'description',\n",
              "  'telesens',\n",
              "  'business',\n",
              "  'analyst',\n",
              "  'dipocket',\n",
              "  'business',\n",
              "  'analyst',\n",
              "  'resty',\n",
              "  'application',\n",
              "  'business',\n",
              "  'analyst',\n",
              "  'product',\n",
              "  'manager',\n",
              "  'project',\n",
              "  'experience',\n",
              "  'years',\n",
              "  'brief',\n",
              "  'project',\n",
              "  'description',\n",
              "  'your',\n",
              "  'roles',\n",
              "  'responsibility',\n",
              "  'antifraud',\n",
              "  'services',\n",
              "  'detecti',\n",
              "  'ng',\n",
              "  'element',\n",
              "  'subscriber',\n",
              "  'fraudulent',\n",
              "  'activity',\n",
              "  'requirements',\n",
              "  'analysis'],\n",
              " ['integration', 'solution']]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenize words in sentences in descriptions\n",
        "resume_tokens = [word_tokenize(sentence) for sentence in resume]\n",
        "position_tokens = [word_tokenize(sentence) for sentence in position]\n",
        "resume_tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S0m-swfrbR8E",
        "outputId": "ae6216df-4043-4a25-aa2a-959d3ae9c51c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['httpswwwamazonjobsenjobsbusinessanalyst',\n",
              "  'description',\n",
              "  'will',\n",
              "  'able',\n",
              "  'determine',\n",
              "  'amazons',\n",
              "  'middle',\n",
              "  'mile',\n",
              "  'automated',\n",
              "  'driver',\n",
              "  'supply',\n",
              "  'planning',\n",
              "  'predicting',\n",
              "  'right',\n",
              "  'number',\n",
              "  'driver',\n",
              "  'shift',\n",
              "  'deliver',\n",
              "  'million',\n",
              "  'package',\n",
              "  'every',\n",
              "  'day',\n",
              "  'customers'],\n",
              " ['as',\n",
              "  'business',\n",
              "  'analyst',\n",
              "  'operate',\n",
              "  'crossroad',\n",
              "  'multiple',\n",
              "  'complex',\n",
              "  'amazon',\n",
              "  'systems',\n",
              "  'getting',\n",
              "  'global',\n",
              "  'visibility',\n",
              "  'amazon',\n",
              "  'move',\n",
              "  'inventory',\n",
              "  'across',\n",
              "  'network',\n",
              "  'serf',\n",
              "  'customers'],\n",
              " ['you',\n",
              "  'work',\n",
              "  'core',\n",
              "  'optimization',\n",
              "  'model',\n",
              "  'drive',\n",
              "  'middle',\n",
              "  'mile',\n",
              "  'planning',\n",
              "  'business',\n",
              "  'amazon'],\n",
              " ['you',\n",
              "  'enable',\n",
              "  'creation',\n",
              "  'product',\n",
              "  'drive',\n",
              "  'evergreater',\n",
              "  'automation',\n",
              "  'scalability',\n",
              "  'optimization',\n",
              "  'every',\n",
              "  'aspect',\n",
              "  'transportation',\n",
              "  'removing',\n",
              "  'cost',\n",
              "  'delivering',\n",
              "  'speed',\n",
              "  'execution',\n",
              "  'customers'],\n",
              " ['the', 'impact', 'work', 'global', 'material', 'remarkable']]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "position_tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1P9s2eB8bR8E"
      },
      "outputs": [],
      "source": [
        "# Create resume and position corpuses\n",
        "corpus_resume = create_corpus(resume)\n",
        "corpus_position = create_corpus(position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27HWYXhNbR8E",
        "outputId": "862648c1-39ee-44f5-83c9-b8148a3ac083"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'page abc abc email abcgmailcom position business analyst system analyst summary id like suggest expertise knowle dge skill my skill instant response change cases proficiency negotiation mediat ion issue solving allow sure ability quickly dive new sphere activity education years educational institution qualification yaroslav mudryi national law university llm professional skills os windows android ios macos ubuntu technologies web mobile dbms ms sql mysql oracle access surface immersion ba support tool jira confluence clicku p ms project google docs enterprise architect ms office etc postman design diagram adobexd invision figma drawio miro methodologies agile scrum kanban waterfall foreign language english upper intermediate other skill idef uml bpmn rest api graphql xml json service records years employer position brief job description telesens business analyst dipocket business analyst resty application business analyst product manager project experience years brief project description your roles responsibility antifraud services detecti ng element subscriber fraudulent activity requirements analysis integration solution tech requirement specifications use case scenarios uml sequence iagrams omnichannel orchestration subscriber activity requirements analysis integration solution tech requirement specifications use case scenarios uml sequence iagrams rbt integration solution requirements analysis tech requirement specifications use case scenarios uml sequence iagrams app development cost calculator requirements analysis product requirements businesstech requirement specifications use case scenarios fitness project tech requirement specifications telesens_cv_template page social net value communication user exchanging video question responds requirements analysis product requirements businesstech requirement specifications use case scenarios legal tech project value automati zation communication court administration participant trials market researching target definition analysis customers business needs product roadmapping analysis sale pipeline customer development requirements analysis requ irements elicitation perform requirement management prioritization traceability verification validation requirements negotiations client partner product facilitation product requirements businesstech requirement specifi cations risk management troubleshooting health care project value optimization automatization functioning ambulance service analysis customers business needs requirements analysis requirements elicitation taking part performing requirement management prioritization traceability verification validation requirements negotiations client partner product facilitation business requirement specifications use case scenarios certificationstraining theory practice mediation course mediation conflictology productman practice course it product management iamba practice course it business analysis supreme ba advanced practice course it business analysis techmind course basic technical knowledge it manager iam scrum practice course scrum techmind practice course it technical skill manager'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnGTyPGObR8E",
        "outputId": "8b7171ff-d5d3-44ad-bdee-b54c3712b35f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'httpswwwamazonjobsenjobsbusinessanalyst description will able determine amazons middle mile automated driver supply planning predicting right number driver shift deliver million package every day customers as business analyst operate crossroad multiple complex amazon systems getting global visibility amazon move inventory across network serf customers you work core optimization model drive middle mile planning business amazon you enable creation product drive evergreater automation scalability optimization every aspect transportation removing cost delivering speed execution customers the impact work global material remarkable the successful candidate voraciously curious amazonâs transportation operation data consumed produced system used improve outcome lower costs your responsibility expose measure current performance systems find quantify opportunity improvement dive deep existing algorithm explain unexpected performance we looking sophisticated user data querying tool expert synthesizing communicating insight recommendation audience varying level technical sophistication the middle mile transportation technology organization build complex software solution work across vendors warehouses carrier optimize time cost getting package delivered our service already handle thousand request per second make business decision impacting billion dollar year integrate network small large carriers owneroperators driver worldwide manage business rule million unique products improve ordering delivery experience million online shoppers that said remains fast growing business technical journey started our mission build efficient optimal transportation solution planet using technology engineering muscle biggest advantage we aim leverage cutting edge technology big data machine learning optimization techniques operate high volume low latency high availability services as member collaborative team opportunity make impact amazon logistics work group talented program managers product managers research scientists software developers business stakeholder design amazon network future key job responsibility perform complex data research identify opportunity reduce fulfillment cost well improve efficiency customer experience supporting business decision making design develop establish kpis provide strategic insight drive growth performance systematically identify data source forecast error follow resolution ensure future plan updated improved business process develop standardized metric evaluate benchmark pertaining short long term network planning forecasting pull report data numerous database using excel sql andor data management systems proven capability dive deep utilize known research problem solving technique communicate complex insight stakeholders verbally writing we open hiring candidate work one following locations luxembourg lux basic qualifications bachelors degree equivalent experience excel including vba pivot tables array functions power pivots etc data visualization tool tableau experience business financial analysis experience defining requirement using data metric draw business insight experience excel experience sql preferred qualifications experience language like tableau python r experience making business recommendation influencing stakeholder'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus_position"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjbLIeI1bR8E"
      },
      "source": [
        "### Section 2: Similarity Computation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cbyb4AalbR8E",
        "outputId": "c0fd8cee-5d89-4289-b2ce-76f65d032bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jaccard similarity: 0.06581740976645435\n",
            "Dice similarity: 0.12350597609561753\n"
          ]
        }
      ],
      "source": [
        "# Binary similarity\n",
        "flatten_position_tokens = sum(position_tokens, [])\n",
        "flatten_resume_tokens = sum(resume_tokens, [])\n",
        "print(\"Jaccard similarity:\", jaccard_sim(flatten_resume_tokens, flatten_position_tokens))\n",
        "print(\"Dice similarity:\", dice_sim(flatten_resume_tokens, flatten_position_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzxF_EXtbR8E"
      },
      "source": [
        "##### Section 2.1. Statistical models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVO_fHzTbR8E"
      },
      "outputs": [],
      "source": [
        "# Bag-of-words word embeddings\n",
        "bow_resume = bag_of_words(corpus_resume, corpus_position)[1]\n",
        "bow_position = bag_of_words(corpus_resume, corpus_position)[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJe4hYRcbR8F",
        "outputId": "df7299c0-de81-4e5f-a5fa-b07884d3444c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 2,  1,  1,  0,  1,  0,  3,  1,  1,  1,  0,  1,  0,  0,  1,  0,  0,\n",
              "        0,  0,  1, 12,  5,  0,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,\n",
              "        1,  0,  1,  0,  2,  0,  1,  0,  0,  0,  0,  1,  2,  0,  9,  3,  1,\n",
              "        0,  0,  1,  0,  0,  6,  1,  1,  1,  1,  1,  2,  0,  0,  0,  2,  0,\n",
              "        1,  1,  0,  0,  1,  0,  7,  1,  0,  0,  0,  0,  1,  2,  0,  0,  0,\n",
              "        0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  0,  2,  1,  1,  0,  0,  0,\n",
              "        2,  1,  1,  1,  1,  1,  0,  0,  1,  0,  0,  0,  1,  1,  0,  0,  1,\n",
              "        2,  1,  1,  0,  0,  1,  0,  1,  0,  0,  0,  1,  0,  0,  0,  0,  1,\n",
              "        0,  0,  1,  0,  1,  0,  0,  2,  0,  1,  0,  0,  1,  0,  0,  0,  0,\n",
              "        1,  1,  0,  1,  0,  0,  0,  0,  1,  1,  0,  0,  0,  0,  1,  0,  0,\n",
              "        0,  3,  1,  1,  1,  1,  0,  1,  0,  0,  0,  0,  0,  0,  0,  0,  1,\n",
              "        1,  0,  3,  1,  0,  1,  1,  1,  1,  1,  5,  1,  1,  0,  1,  1,  0,\n",
              "        1,  1,  0,  0,  1,  0,  0,  1,  0,  1,  0,  0,  1,  1,  0,  0,  0,\n",
              "        0,  0,  0,  0,  0,  0,  1,  0,  0,  0,  4,  3,  0,  1,  0,  0,  1,\n",
              "        2,  0,  1,  0,  0,  0,  0,  1,  0,  1,  0,  0,  3,  1,  0,  0,  1,\n",
              "        1,  1,  2,  1,  2,  1,  0,  1,  1,  0,  0,  1,  1,  0,  0,  0,  0,\n",
              "        0,  0,  0,  1,  0,  1,  1,  0,  0,  1,  1,  0,  0,  0,  0,  0,  2,\n",
              "        1,  1,  2,  0,  1,  0,  1,  0,  1,  0,  0,  0,  0,  0,  2,  1,  0,\n",
              "        6,  0,  0,  2,  0,  0,  0,  8,  1,  0,  1,  1,  0,  6,  0,  0,  0,\n",
              "        0,  1,  0,  0,  0,  1,  1,  0,  1,  0,  1,  0,  0,  0,  0,  0,  1,\n",
              "        0, 10, 13,  0,  1,  0,  1,  1,  1,  1,  1,  0,  1,  1,  1,  0,  0,\n",
              "        1,  0,  6,  0,  3,  0,  3,  0,  2,  1,  0,  0,  0,  4,  1,  0,  1,\n",
              "        0,  3,  1,  0,  0,  0,  1,  7,  0,  1,  1,  0,  0,  0,  0,  0,  2,\n",
              "        0,  1,  1,  0,  1,  0,  1,  1,  1,  0,  1,  0,  0,  0,  0,  1,  0,\n",
              "        1,  0,  5,  2,  2,  0,  0,  1,  0,  1,  1,  0,  0,  0,  1,  0,  0,\n",
              "        1,  2,  0,  1,  1,  1,  4,  0,  0,  1,  0,  1,  6,  0,  1,  0,  0,\n",
              "        2,  3,  0,  0,  0,  0,  2,  1,  0,  0,  0,  0,  0,  1,  0,  1,  0,\n",
              "        0,  1,  0,  0,  0,  1,  1,  0,  3,  0,  1,  1], dtype=int64)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kqpj1VVPbR8F",
        "outputId": "dcc148b1-1a84-44fd-fd08-1bbb52173f6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0,  0,  0,  1,  0,  2,  0,  0,  0,  0,  1,  0,  1,  1,  0,  1,  5,\n",
              "        1,  1,  0,  1,  1,  1,  0,  0,  0,  0,  0,  0,  1,  2,  1,  1,  1,\n",
              "        0,  1,  0,  1,  0,  1,  1,  1,  1,  1,  1,  0,  0,  2, 11,  0,  0,\n",
              "        2,  1,  0,  1,  1,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  0,  4,\n",
              "        0,  0,  1,  1,  3,  1,  0,  0,  1,  1,  1,  1,  1,  3,  1,  9,  1,\n",
              "        1,  0,  2,  2,  1,  0,  1,  1,  1,  1,  1,  1,  2,  0,  1,  2,  1,\n",
              "        0,  0,  0,  0,  2,  0,  1,  1,  0,  3,  3,  1,  0,  0,  1,  1,  0,\n",
              "        0,  0,  0,  1,  1,  0,  1,  0,  1,  1,  1,  1,  1,  1,  2,  3,  0,\n",
              "        1,  1,  9,  1,  0,  1,  1,  0,  1,  0,  1,  1,  0,  1,  1,  1,  1,\n",
              "        0,  0,  1,  0,  1,  2,  2,  2,  0,  0,  1,  1,  1,  1,  0,  2,  1,\n",
              "        1,  0,  0,  0,  0,  0,  2,  0,  2,  1,  3,  1,  1,  1,  1,  4,  0,\n",
              "        0,  1,  0,  0,  1,  0,  0,  0,  0,  0,  0,  0,  1,  1,  0,  0,  1,\n",
              "        0,  0,  1,  1,  1,  1,  1,  0,  1,  0,  1,  1,  1,  0,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  0,  2,  2,  1,  1,  0,  2,  0,  1,  1,  0,\n",
              "        0,  1,  0,  2,  3,  3,  3,  0,  1,  0,  1,  1,  0,  0,  1,  1,  0,\n",
              "        0,  0,  0,  0,  0,  0,  4,  0,  0,  1,  1,  0,  0,  1,  1,  1,  2,\n",
              "        1,  3,  1,  3,  1,  0,  0,  1,  1,  0,  0,  2,  1,  1,  0,  2,  0,\n",
              "        0,  0,  0,  1,  1,  3,  0,  1,  0,  1,  1,  1,  1,  3,  0,  0,  1,\n",
              "        0,  1,  1,  0,  1,  1,  1,  2,  0,  1,  0,  0,  1,  0,  1,  1,  1,\n",
              "        1,  0,  2,  1,  1,  0,  0,  0,  0,  2,  0,  1,  1,  1,  1,  1,  0,\n",
              "        1,  1,  0,  3,  0,  1,  0,  0,  2,  0,  0,  1,  0,  0,  0,  1,  1,\n",
              "        0,  1,  0,  1,  0,  1,  0,  1,  1,  1,  1,  1,  1,  0,  0,  1,  0,\n",
              "        2,  2,  1,  1,  1,  1,  0,  0,  1,  0,  2,  2,  1,  1,  1,  1,  0,\n",
              "        1,  0,  0,  1,  0,  1,  0,  0,  0,  1,  1,  1,  3,  2,  1,  0,  1,\n",
              "        0,  1,  0,  0,  2,  1,  1,  0,  3,  0,  0,  1,  1,  3,  0,  1,  1,\n",
              "        2,  0,  4,  0,  0,  0,  0,  1,  1,  0,  1,  0,  0,  1,  1,  3,  1,\n",
              "        0,  0,  1,  1,  1,  1,  0,  0,  1,  1,  1,  1,  1,  0,  3,  0,  1,\n",
              "        1,  0,  5,  1,  1,  0,  0,  1,  0,  2,  1,  0], dtype=int64)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bow_position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFtNnn9obR8F",
        "outputId": "5232d34b-7bdb-4d41-dde7-875a5727a1dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bag-of-words cosine similarity: 0.183583553976399\n",
            "Bag-of-words sqrt-cos similarity: nan\n",
            "Bag-of-words improved sqrt-cos similarity: 0.4284665144167032\n"
          ]
        }
      ],
      "source": [
        "# Bag-of-words word embeddings similarity\n",
        "print(\"Bag-of-words cosine similarity:\", cos_sim(bow_resume, bow_position))\n",
        "print(\"Bag-of-words sqrt-cos similarity:\", sqrt_cos_sim(normalize_vector(bow_resume), normalize_vector(bow_position)))\n",
        "print(\"Bag-of-words improved sqrt-cos similarity:\", improved_sqrt_cos_sim(bow_resume, bow_position))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccV4dvMpbR8F"
      },
      "outputs": [],
      "source": [
        "# Tf-idf word embeddings\n",
        "tf_idf_resume = tf_idf(corpus_resume, corpus_position)[1]\n",
        "tf_idf_position = tf_idf(corpus_resume, corpus_position)[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N82y_WShbR8F",
        "outputId": "d95fa6ab-95cb-4bf8-b6d8-ba5570001d66"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.06073262, 0.03036631, 0.03036631, 0.        , 0.03036631,\n",
              "       0.        , 0.09109894, 0.03036631, 0.03036631, 0.03036631,\n",
              "       0.        , 0.03036631, 0.        , 0.        , 0.03036631,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03036631,\n",
              "       0.25927057, 0.10802941, 0.        , 0.03036631, 0.03036631,\n",
              "       0.03036631, 0.03036631, 0.03036631, 0.03036631, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03036631,\n",
              "       0.        , 0.03036631, 0.        , 0.06073262, 0.        ,\n",
              "       0.02160588, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.03036631, 0.06073262, 0.        , 0.19445293, 0.09109894,\n",
              "       0.03036631, 0.        , 0.        , 0.03036631, 0.        ,\n",
              "       0.        , 0.18219787, 0.03036631, 0.03036631, 0.03036631,\n",
              "       0.03036631, 0.03036631, 0.06073262, 0.        , 0.        ,\n",
              "       0.        , 0.06073262, 0.        , 0.03036631, 0.03036631,\n",
              "       0.        , 0.        , 0.02160588, 0.        , 0.21256419,\n",
              "       0.03036631, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.02160588, 0.04321176, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.03036631, 0.        , 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.04321176, 0.02160588, 0.03036631, 0.        ,\n",
              "       0.        , 0.        , 0.06073262, 0.03036631, 0.03036631,\n",
              "       0.03036631, 0.02160588, 0.03036631, 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.        , 0.03036631,\n",
              "       0.03036631, 0.        , 0.        , 0.03036631, 0.06073262,\n",
              "       0.03036631, 0.03036631, 0.        , 0.        , 0.03036631,\n",
              "       0.        , 0.03036631, 0.        , 0.        , 0.        ,\n",
              "       0.02160588, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.02160588, 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.06073262, 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.03036631, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03036631, 0.03036631,\n",
              "       0.        , 0.03036631, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.03036631, 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.09109894, 0.03036631, 0.03036631, 0.03036631,\n",
              "       0.03036631, 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.03036631, 0.03036631, 0.        , 0.09109894,\n",
              "       0.03036631, 0.        , 0.03036631, 0.03036631, 0.03036631,\n",
              "       0.03036631, 0.03036631, 0.15183156, 0.03036631, 0.02160588,\n",
              "       0.        , 0.03036631, 0.03036631, 0.        , 0.03036631,\n",
              "       0.03036631, 0.        , 0.        , 0.02160588, 0.        ,\n",
              "       0.        , 0.03036631, 0.        , 0.03036631, 0.        ,\n",
              "       0.        , 0.02160588, 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.08642352, 0.09109894, 0.        , 0.03036631,\n",
              "       0.        , 0.        , 0.03036631, 0.06073262, 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.09109894, 0.03036631, 0.        , 0.        , 0.03036631,\n",
              "       0.03036631, 0.03036631, 0.06073262, 0.03036631, 0.06073262,\n",
              "       0.03036631, 0.        , 0.03036631, 0.03036631, 0.        ,\n",
              "       0.        , 0.03036631, 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.02160588, 0.        , 0.03036631, 0.03036631, 0.        ,\n",
              "       0.        , 0.03036631, 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.06073262, 0.03036631,\n",
              "       0.03036631, 0.06073262, 0.        , 0.02160588, 0.        ,\n",
              "       0.03036631, 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.06073262, 0.03036631,\n",
              "       0.        , 0.18219787, 0.        , 0.        , 0.06073262,\n",
              "       0.        , 0.        , 0.        , 0.17284705, 0.03036631,\n",
              "       0.        , 0.03036631, 0.03036631, 0.        , 0.18219787,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03036631,\n",
              "       0.        , 0.        , 0.        , 0.03036631, 0.03036631,\n",
              "       0.        , 0.03036631, 0.        , 0.03036631, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03036631,\n",
              "       0.        , 0.21605881, 0.39476206, 0.        , 0.03036631,\n",
              "       0.        , 0.03036631, 0.03036631, 0.02160588, 0.03036631,\n",
              "       0.03036631, 0.        , 0.03036631, 0.03036631, 0.03036631,\n",
              "       0.        , 0.        , 0.03036631, 0.        , 0.18219787,\n",
              "       0.        , 0.09109894, 0.        , 0.09109894, 0.        ,\n",
              "       0.04321176, 0.02160588, 0.        , 0.        , 0.        ,\n",
              "       0.12146525, 0.03036631, 0.        , 0.03036631, 0.        ,\n",
              "       0.06481764, 0.02160588, 0.        , 0.        , 0.        ,\n",
              "       0.03036631, 0.21256419, 0.        , 0.03036631, 0.02160588,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.06073262, 0.        , 0.03036631, 0.03036631, 0.        ,\n",
              "       0.03036631, 0.        , 0.03036631, 0.03036631, 0.03036631,\n",
              "       0.        , 0.02160588, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.03036631, 0.        , 0.03036631, 0.        ,\n",
              "       0.15183156, 0.06073262, 0.04321176, 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.03036631, 0.03036631, 0.        ,\n",
              "       0.        , 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.02160588, 0.06073262, 0.        , 0.03036631, 0.03036631,\n",
              "       0.03036631, 0.12146525, 0.        , 0.        , 0.03036631,\n",
              "       0.        , 0.03036631, 0.18219787, 0.        , 0.02160588,\n",
              "       0.        , 0.        , 0.06073262, 0.09109894, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.06073262, 0.03036631,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.03036631, 0.        , 0.        ,\n",
              "       0.03036631, 0.        , 0.        , 0.        , 0.03036631,\n",
              "       0.03036631, 0.        , 0.09109894, 0.        , 0.02160588,\n",
              "       0.03036631])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w95KJbM2bR8F",
        "outputId": "d3056e6b-90de-465b-ae15-7098b748bed3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.03559548, 0.        ,\n",
              "       0.07119097, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.03559548, 0.        , 0.03559548, 0.03559548, 0.        ,\n",
              "       0.03559548, 0.17797741, 0.03559548, 0.03559548, 0.        ,\n",
              "       0.02532648, 0.02532648, 0.03559548, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.03559548,\n",
              "       0.07119097, 0.03559548, 0.03559548, 0.03559548, 0.        ,\n",
              "       0.03559548, 0.        , 0.03559548, 0.        , 0.03559548,\n",
              "       0.02532648, 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.        , 0.        , 0.07119097, 0.27859127, 0.        ,\n",
              "       0.        , 0.07119097, 0.03559548, 0.        , 0.03559548,\n",
              "       0.03559548, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.        , 0.14238193, 0.        , 0.        ,\n",
              "       0.03559548, 0.03559548, 0.07597944, 0.03559548, 0.        ,\n",
              "       0.        , 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.02532648, 0.07597944, 0.03559548, 0.32035934, 0.03559548,\n",
              "       0.03559548, 0.        , 0.07119097, 0.07119097, 0.03559548,\n",
              "       0.        , 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.02532648, 0.05065296, 0.        , 0.03559548,\n",
              "       0.07119097, 0.03559548, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.05065296, 0.        , 0.03559548, 0.03559548,\n",
              "       0.        , 0.10678645, 0.10678645, 0.03559548, 0.        ,\n",
              "       0.        , 0.03559548, 0.03559548, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03559548, 0.03559548, 0.        ,\n",
              "       0.03559548, 0.        , 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.02532648, 0.03559548, 0.03559548, 0.07119097, 0.10678645,\n",
              "       0.        , 0.03559548, 0.03559548, 0.22793831, 0.03559548,\n",
              "       0.        , 0.03559548, 0.03559548, 0.        , 0.03559548,\n",
              "       0.        , 0.03559548, 0.03559548, 0.        , 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.        , 0.        ,\n",
              "       0.03559548, 0.        , 0.03559548, 0.07119097, 0.07119097,\n",
              "       0.07119097, 0.        , 0.        , 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.        , 0.07119097, 0.03559548,\n",
              "       0.03559548, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.07119097, 0.        , 0.07119097, 0.03559548,\n",
              "       0.10678645, 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.14238193, 0.        , 0.        , 0.03559548, 0.        ,\n",
              "       0.        , 0.03559548, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.02532648,\n",
              "       0.03559548, 0.        , 0.        , 0.03559548, 0.        ,\n",
              "       0.        , 0.03559548, 0.03559548, 0.02532648, 0.03559548,\n",
              "       0.03559548, 0.        , 0.03559548, 0.        , 0.03559548,\n",
              "       0.03559548, 0.02532648, 0.        , 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.        , 0.07119097, 0.07119097,\n",
              "       0.03559548, 0.02532648, 0.        , 0.07119097, 0.        ,\n",
              "       0.03559548, 0.03559548, 0.        , 0.        , 0.03559548,\n",
              "       0.        , 0.07119097, 0.10678645, 0.10678645, 0.10678645,\n",
              "       0.        , 0.03559548, 0.        , 0.03559548, 0.03559548,\n",
              "       0.        , 0.        , 0.03559548, 0.03559548, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.14238193, 0.        , 0.        , 0.03559548,\n",
              "       0.03559548, 0.        , 0.        , 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.07119097, 0.03559548, 0.10678645, 0.03559548,\n",
              "       0.07597944, 0.03559548, 0.        , 0.        , 0.03559548,\n",
              "       0.03559548, 0.        , 0.        , 0.07119097, 0.03559548,\n",
              "       0.03559548, 0.        , 0.07119097, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03559548, 0.02532648, 0.10678645,\n",
              "       0.        , 0.03559548, 0.        , 0.03559548, 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.10678645, 0.        , 0.        ,\n",
              "       0.03559548, 0.        , 0.03559548, 0.03559548, 0.        ,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.05065296, 0.        ,\n",
              "       0.03559548, 0.        , 0.        , 0.03559548, 0.        ,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.03559548, 0.        ,\n",
              "       0.07119097, 0.03559548, 0.03559548, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.07119097, 0.        , 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.03559548, 0.        ,\n",
              "       0.03559548, 0.02532648, 0.        , 0.10678645, 0.        ,\n",
              "       0.03559548, 0.        , 0.        , 0.05065296, 0.        ,\n",
              "       0.        , 0.03559548, 0.        , 0.        , 0.        ,\n",
              "       0.03559548, 0.03559548, 0.        , 0.03559548, 0.        ,\n",
              "       0.03559548, 0.        , 0.03559548, 0.        , 0.03559548,\n",
              "       0.02532648, 0.02532648, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.        , 0.        , 0.03559548, 0.        , 0.07119097,\n",
              "       0.05065296, 0.02532648, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.        , 0.        , 0.03559548, 0.        , 0.05065296,\n",
              "       0.07119097, 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.        , 0.03559548, 0.        , 0.        , 0.03559548,\n",
              "       0.        , 0.03559548, 0.        , 0.        , 0.        ,\n",
              "       0.03559548, 0.02532648, 0.03559548, 0.10678645, 0.07119097,\n",
              "       0.03559548, 0.        , 0.03559548, 0.        , 0.03559548,\n",
              "       0.        , 0.        , 0.05065296, 0.03559548, 0.03559548,\n",
              "       0.        , 0.10678645, 0.        , 0.        , 0.03559548,\n",
              "       0.03559548, 0.10678645, 0.        , 0.03559548, 0.03559548,\n",
              "       0.05065296, 0.        , 0.14238193, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.03559548, 0.03559548, 0.        ,\n",
              "       0.03559548, 0.        , 0.        , 0.03559548, 0.02532648,\n",
              "       0.10678645, 0.03559548, 0.        , 0.        , 0.03559548,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.        , 0.        ,\n",
              "       0.03559548, 0.03559548, 0.03559548, 0.03559548, 0.03559548,\n",
              "       0.        , 0.10678645, 0.        , 0.03559548, 0.03559548,\n",
              "       0.        , 0.17797741, 0.03559548, 0.03559548, 0.        ,\n",
              "       0.        , 0.03559548, 0.        , 0.07119097, 0.02532648,\n",
              "       0.        ])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf_idf_position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A41geKrzbR8G",
        "outputId": "d4c3aafc-4045-4927-d9b0-1b54543d50f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tf-idf cosine similarity: 0.11108178270708521\n",
            "Tf-idf sqrt-cos similarity: nan\n",
            "Tf-idf improved sqrt-cos similarity: 0.33328933782388726\n"
          ]
        }
      ],
      "source": [
        "# Tf-idf word embeddings similarity\n",
        "print(\"Tf-idf cosine similarity:\", cos_sim(tf_idf_resume, tf_idf_position))\n",
        "print(\"Tf-idf sqrt-cos similarity:\", sqrt_cos_sim(normalize_vector(tf_idf_resume), normalize_vector(tf_idf_position)))\n",
        "print(\"Tf-idf improved sqrt-cos similarity:\", improved_sqrt_cos_sim(tf_idf_resume, tf_idf_position))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm7JIr8ybR8G"
      },
      "source": [
        "##### Section 2.2. Deep Learning models (without context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Shz9-_Z1bR8G"
      },
      "outputs": [],
      "source": [
        "# Build Deep Learning models (without context)\n",
        "model_w2v = build_model_ncontext(model_path=\"word2vec-google-news-300.model\")\n",
        "model_glove = build_model_ncontext(model_path=\"glove-wiki-gigaword-300.model\")\n",
        "model_fasttext = build_model_ncontext(model_path=\"fasttext-wiki-news-subwords-300.model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RJiubpGbR8G",
        "outputId": "b5e9db28-3951-4066-bd88-add7fd772e3a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.80664062e-02,  8.54492188e-03,  6.98242188e-02,  3.07617188e-02,\n",
              "        8.05664062e-02,  3.44238281e-02,  4.41406250e-01,  1.91650391e-02,\n",
              "        1.10473633e-02,  9.13085938e-02, -8.05664062e-02,  8.66699219e-03,\n",
              "       -5.66406250e-02, -2.79296875e-01, -3.04687500e-01,  2.66113281e-02,\n",
              "       -1.01074219e-01, -2.44140625e-01,  1.10473633e-02, -2.19726562e-02,\n",
              "       -1.27929688e-01,  2.11914062e-01, -4.27246094e-02,  6.34765625e-02,\n",
              "       -6.12792969e-02, -1.52343750e-01, -4.27246094e-02, -1.40625000e-01,\n",
              "       -2.41699219e-02, -1.74804688e-01,  1.55639648e-02, -4.61425781e-02,\n",
              "       -1.83593750e-01, -8.74023438e-02,  1.27929688e-01, -1.05957031e-01,\n",
              "        7.26318359e-03, -2.64892578e-02,  1.35742188e-01, -1.41601562e-01,\n",
              "       -1.19628906e-02,  2.43164062e-01,  5.61523438e-02,  1.40625000e-01,\n",
              "       -3.22265625e-01, -3.39843750e-01, -2.53906250e-01, -1.36718750e-01,\n",
              "       -2.08984375e-01,  3.61328125e-01,  1.34765625e-01, -1.11816406e-01,\n",
              "       -1.14257812e-01, -2.27539062e-01,  9.66796875e-02, -6.73828125e-02,\n",
              "       -3.08837891e-02, -3.17382812e-02,  1.79443359e-02, -4.10156250e-02,\n",
              "        7.95898438e-02, -1.30859375e-01, -4.56542969e-02, -1.52343750e-01,\n",
              "       -1.05957031e-01,  6.29882812e-02, -3.32031250e-02, -7.81250000e-02,\n",
              "        9.47265625e-02,  3.08837891e-02, -8.69140625e-02, -1.71875000e-01,\n",
              "       -1.13281250e-01, -1.06445312e-01,  1.02539062e-01,  6.78710938e-02,\n",
              "       -5.90820312e-02,  1.09863281e-02, -1.96289062e-01,  2.28515625e-01,\n",
              "       -1.02050781e-01, -1.04003906e-01, -7.42187500e-02,  4.68750000e-02,\n",
              "        1.18652344e-01,  9.22851562e-02, -1.83593750e-01,  1.00097656e-01,\n",
              "        2.43164062e-01, -1.92871094e-02,  1.47460938e-01, -1.01074219e-01,\n",
              "       -3.07617188e-02, -4.93164062e-02, -1.18652344e-01,  5.66406250e-02,\n",
              "       -1.81640625e-01, -2.27928162e-04,  5.78613281e-02,  8.93554688e-02,\n",
              "        6.39648438e-02,  3.75976562e-02, -9.61914062e-02, -1.79687500e-01,\n",
              "        2.34375000e-02,  2.51953125e-01, -1.39648438e-01, -1.36718750e-01,\n",
              "        1.25976562e-01,  1.46484375e-02,  1.37695312e-01, -4.10156250e-02,\n",
              "        2.48046875e-01,  8.88671875e-02,  1.66992188e-01, -2.02636719e-02,\n",
              "       -5.68847656e-02, -1.22558594e-01,  8.25195312e-02, -1.50756836e-02,\n",
              "       -5.71289062e-02, -4.54101562e-02, -2.16796875e-01,  3.37890625e-01,\n",
              "       -1.94335938e-01,  8.25195312e-02, -2.59765625e-01, -1.14257812e-01,\n",
              "       -2.07031250e-01, -1.53808594e-02,  2.36816406e-02,  3.03955078e-02,\n",
              "        9.42382812e-02, -1.96289062e-01,  1.41601562e-01,  2.19726562e-01,\n",
              "       -3.66210938e-02,  9.37500000e-02,  6.49414062e-02,  1.67968750e-01,\n",
              "       -8.00781250e-02, -4.34570312e-02, -1.23046875e-01, -7.81250000e-03,\n",
              "        7.95898438e-02, -1.77734375e-01, -1.86523438e-01,  5.83496094e-02,\n",
              "       -1.90429688e-01, -2.61718750e-01,  1.44531250e-01, -3.08593750e-01,\n",
              "        2.55859375e-01,  3.57421875e-01,  1.30859375e-01,  1.89453125e-01,\n",
              "       -1.55639648e-02,  9.91210938e-02,  3.12805176e-03, -9.96093750e-02,\n",
              "        5.78613281e-02,  9.91210938e-02,  1.44531250e-01,  3.92578125e-01,\n",
              "       -1.55273438e-01,  1.27929688e-01,  3.92578125e-01, -3.54003906e-02,\n",
              "        5.17578125e-02,  3.55529785e-03,  3.28063965e-03, -1.30859375e-01,\n",
              "        4.51660156e-02,  2.76184082e-03,  1.36718750e-01, -1.11083984e-02,\n",
              "       -1.84326172e-02, -1.22070312e-01,  6.54296875e-02,  2.02148438e-01,\n",
              "       -1.20117188e-01,  1.93786621e-03, -2.09960938e-01, -9.52148438e-02,\n",
              "       -4.29687500e-02, -7.22656250e-02,  6.78710938e-02, -2.84423828e-02,\n",
              "       -6.29882812e-02,  6.17675781e-02, -2.63671875e-01, -8.74023438e-02,\n",
              "        7.86132812e-02, -4.15039062e-02, -2.46093750e-01, -2.57568359e-02,\n",
              "        4.98046875e-02,  1.35742188e-01,  8.62121582e-04,  5.31005859e-03,\n",
              "        1.06445312e-01,  9.13085938e-02,  1.01562500e-01,  2.03857422e-02,\n",
              "       -1.18652344e-01,  1.82617188e-01, -4.88281250e-02,  4.15039062e-03,\n",
              "        2.75390625e-01,  1.95312500e-01, -5.27343750e-02, -1.46484375e-01,\n",
              "       -1.15722656e-01,  4.51660156e-02,  9.21630859e-03,  1.45874023e-02,\n",
              "        1.91406250e-01, -4.90722656e-02, -2.81982422e-02,  8.39843750e-02,\n",
              "        1.62353516e-02, -4.10156250e-02,  7.51953125e-02,  2.05078125e-01,\n",
              "       -8.25195312e-02, -7.76367188e-02, -1.56250000e-01,  2.83203125e-01,\n",
              "       -1.13281250e-01, -1.01562500e-01,  8.20312500e-02, -2.57568359e-02,\n",
              "       -2.96875000e-01, -2.18750000e-01,  4.97436523e-03,  6.64062500e-02,\n",
              "        1.53320312e-01, -1.72119141e-02,  2.46093750e-01, -5.73730469e-02,\n",
              "       -6.54296875e-02, -4.54101562e-02,  1.45507812e-01, -9.27734375e-02,\n",
              "        7.71484375e-02, -1.64062500e-01,  1.94335938e-01, -1.53320312e-01,\n",
              "       -1.82617188e-01,  3.06396484e-02, -5.12695312e-02, -1.27563477e-02,\n",
              "       -4.19921875e-02,  1.51977539e-02,  9.57031250e-02, -3.00292969e-02,\n",
              "        9.81445312e-02,  2.42187500e-01, -3.39843750e-01, -1.70898438e-01,\n",
              "       -1.03027344e-01, -8.83789062e-02, -1.82617188e-01,  7.03125000e-02,\n",
              "        1.09863281e-01,  2.81250000e-01, -1.92382812e-01, -1.15722656e-01,\n",
              "       -2.71484375e-01,  2.23632812e-01,  2.39562988e-03, -2.73437500e-01,\n",
              "        3.32031250e-02, -5.41992188e-02, -5.17578125e-02, -1.23046875e-01,\n",
              "        9.39941406e-03, -2.63671875e-02, -2.01171875e-01, -7.51953125e-02,\n",
              "        1.74560547e-02, -1.61132812e-02,  7.17163086e-03,  2.57812500e-01,\n",
              "        1.30859375e-01, -4.76837158e-04, -1.60156250e-01, -6.64062500e-02,\n",
              "        2.37304688e-01, -3.80859375e-02, -3.35937500e-01,  4.51660156e-02,\n",
              "       -1.10839844e-01,  1.01562500e-01, -4.57763672e-03,  4.76074219e-02,\n",
              "       -1.28906250e-01, -1.25000000e-01, -5.61523438e-02, -1.08398438e-01],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \"Project\" word embedding derieved by Word2Vec\n",
        "model_w2v[\"project\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqSwo5IVbR8G",
        "outputId": "2ca75b07-265e-424a-dc3d-cd7d4bb812f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-2.0397e-01, -3.5959e-02, -2.4745e-01, -5.5419e-01,  6.7167e-03,\n",
              "       -8.7778e-02,  2.3057e-01, -3.3634e-01, -2.1594e-01, -1.3637e+00,\n",
              "        2.1076e-01, -4.4217e-01,  2.1688e-01,  2.5215e-01,  3.8284e-01,\n",
              "        1.7151e-02,  7.5829e-02,  1.8668e-01,  2.5643e-01,  4.7164e-01,\n",
              "       -3.0530e-01,  1.8262e-01, -1.3302e-01,  2.1855e-01, -3.9873e-02,\n",
              "        1.9053e-01,  3.3508e-01,  1.9015e-01, -1.5546e-02,  2.3514e-01,\n",
              "        7.2200e-01,  2.9326e-01, -2.7213e-01,  5.2866e-01, -1.2719e-01,\n",
              "        2.0123e-01, -2.4419e-01, -7.9395e-02,  3.3330e-01,  1.3958e-02,\n",
              "       -2.7907e-01, -3.7687e-01, -3.3006e-01,  3.0789e-01, -1.2030e-01,\n",
              "       -2.8289e-01, -8.8605e-02,  1.3664e-01, -1.6403e-01, -6.1411e-02,\n",
              "        1.9604e-01,  1.0830e-01, -3.6917e-01,  1.8505e-03, -2.9781e-01,\n",
              "        3.5050e-01,  4.3316e-01,  4.4869e-01, -1.3611e-01,  1.3710e-01,\n",
              "       -8.4922e-01,  3.1850e-01, -4.3727e-02, -5.8593e-01,  5.6550e-02,\n",
              "        8.6663e-01,  4.2441e-01,  3.1674e-01,  5.9644e-02, -2.1432e-01,\n",
              "        3.1859e-01,  3.8106e-01,  4.1974e-01,  4.1758e-01,  1.6028e-02,\n",
              "        4.7135e-01,  1.0524e-01,  4.9912e-01,  1.0450e-01,  4.2008e-01,\n",
              "       -2.4356e-01, -2.5552e-01,  2.7805e-01, -3.8094e-01,  3.3754e-01,\n",
              "        6.5928e-02, -1.6434e-01,  4.8974e-01,  3.6647e-01, -8.2567e-01,\n",
              "       -2.8254e-01,  6.2603e-02, -3.3515e-02, -2.4739e-01,  1.5371e-01,\n",
              "       -5.5605e-01, -1.5949e-01, -3.9570e-01, -4.1157e-02, -7.5311e-01,\n",
              "       -2.5368e-01, -2.4810e-01,  3.2981e-01, -2.1247e-01,  4.6163e-01,\n",
              "       -1.3924e-01,  3.8115e-02,  2.6646e-01, -1.0736e-01, -5.9766e-01,\n",
              "        1.6200e-01, -6.8731e-01, -4.3474e-01,  5.2374e-02, -1.7447e-01,\n",
              "       -1.9851e-01,  1.6572e-01, -3.3374e-01,  2.3170e-01,  2.3163e-02,\n",
              "       -3.7853e-01,  1.6136e-01, -1.9135e-01,  2.3605e-01,  4.8257e-01,\n",
              "       -3.6414e-01,  2.0539e-04,  2.3195e-01, -3.7186e-01, -7.1814e-02,\n",
              "        2.6602e-01, -8.2448e-02,  6.4702e-01,  1.1191e-02, -6.8356e-02,\n",
              "        1.6886e-02, -4.2168e-01, -2.7580e-01, -3.4925e-01, -5.1142e-01,\n",
              "        3.6726e-01, -3.5122e-02,  6.2521e-01, -1.3248e-01, -8.2734e-03,\n",
              "       -3.0273e-01,  3.2068e-01,  4.7160e-02, -1.2623e-01,  2.6648e-01,\n",
              "        5.6839e-01,  1.8310e-01,  7.2495e-02, -1.7617e-01,  9.9639e-02,\n",
              "        2.2911e-01, -7.1569e-02, -6.0433e-03, -9.3716e-01,  1.6631e-01,\n",
              "       -3.0307e-01, -2.0289e-01,  7.4045e-03,  3.0893e-01, -3.0618e-02,\n",
              "       -5.1045e-01, -1.9603e-01,  2.0277e-01, -4.3709e-01,  5.6567e-01,\n",
              "        4.7061e-01, -4.9635e-01, -5.0913e-01, -7.7369e-01,  5.0896e-02,\n",
              "        4.2738e-01, -3.1582e-01, -1.9339e-01, -7.5247e-02, -1.3827e-01,\n",
              "       -3.6868e-01,  3.9174e-01,  1.2326e-01,  1.0427e-01, -2.4818e-01,\n",
              "       -3.2048e-01,  7.4130e-02, -9.6725e-02,  9.0234e-02, -4.6765e-01,\n",
              "        1.4071e-03,  5.8860e-01, -4.4946e-01,  3.3885e-01, -6.0756e-01,\n",
              "        3.3572e-01, -1.6301e-01,  1.4508e-02,  1.6533e-01, -1.7145e-01,\n",
              "        7.9559e-01, -6.0492e-03,  4.4435e-02, -1.3633e-01,  2.6128e-02,\n",
              "        2.0488e-01, -4.7256e-02,  2.0920e-01,  6.3561e-01,  3.6364e-01,\n",
              "        3.9808e-01, -1.2316e-01,  5.7745e-02, -4.8750e-01,  1.6598e-01,\n",
              "        3.6345e-01, -2.8491e-01,  4.1924e-01,  7.0211e-02,  3.0852e-01,\n",
              "        4.9696e-01, -3.1795e-01, -3.8511e-01,  3.4087e-01,  2.5234e-01,\n",
              "       -2.4873e-01, -3.2537e-02, -1.0871e-01, -5.2282e-01, -1.8538e-01,\n",
              "        5.6150e-02,  1.0370e-01, -6.3808e-01,  1.3097e-01,  3.7513e-01,\n",
              "        7.9660e-02, -3.3749e-01,  8.1252e-02,  2.6972e-02, -3.8277e-01,\n",
              "        4.1449e-01,  6.0653e-02,  1.8743e-01, -1.2483e-01, -1.4313e+00,\n",
              "        6.1829e-01, -6.1430e-02, -5.3853e-01,  2.7045e-02, -1.7246e-03,\n",
              "       -2.2739e-01,  3.4895e-01, -8.6107e-02,  2.5431e-01,  2.9941e-01,\n",
              "       -5.9102e-02,  6.6641e-02,  2.4899e-01,  3.0118e-01,  2.0001e-01,\n",
              "        2.5010e-01,  5.1313e-01,  2.8306e-01, -1.6362e-01,  1.1705e-01,\n",
              "        4.1320e-01,  7.7459e-02,  1.0399e-02,  2.6514e-01,  2.4251e-01,\n",
              "        3.3386e-01, -2.1010e-01,  1.9087e-01, -2.9917e-01, -2.0893e-01,\n",
              "       -2.0170e-02, -1.9026e+00, -2.0888e-01,  7.8513e-01,  2.3326e-01,\n",
              "       -2.2107e-01, -6.9110e-02, -3.8592e-01, -2.7829e-01, -1.8754e-01,\n",
              "        2.5594e-01,  1.4999e-01, -1.8555e-01, -3.9176e-01, -3.2349e-01,\n",
              "       -3.6894e-01, -4.2976e-01, -5.7471e-01,  1.2859e-01,  5.8113e-01,\n",
              "        5.0085e-01,  1.8649e-01, -2.0810e-01, -6.0817e-03,  1.7377e-01],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \"Project\" word embedding derieved by GloVe\n",
        "model_glove[\"project\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_NZjXvuobR8G",
        "outputId": "436f03eb-12e3-4c1a-9b6d-738a17be3fde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 3.6720e-02, -4.6776e-02,  1.1238e-02, -1.4262e-02, -3.9045e-02,\n",
              "       -3.1122e-04,  2.3092e-02, -9.4404e-02,  1.0284e-02,  1.8978e-02,\n",
              "       -2.3707e-02, -7.2466e-02,  4.2775e-02, -5.9705e-03,  2.7818e-02,\n",
              "        1.2642e-02,  1.0934e-01,  2.6429e-02,  5.4367e-02,  4.7241e-05,\n",
              "       -1.2384e-02,  4.0120e-02, -3.6997e-02,  5.7316e-02,  3.5739e-02,\n",
              "       -1.9788e-02, -4.6655e-02,  3.0372e-02, -1.7557e-02, -5.2527e-03,\n",
              "       -2.3609e-02,  5.6846e-03,  9.2050e-03, -9.4131e-02, -8.8816e-03,\n",
              "       -6.2144e-04,  9.2826e-03,  1.8940e-02, -7.2345e-03, -5.3008e-02,\n",
              "       -1.7007e-02, -8.6123e-02, -6.8775e-02, -1.8025e-02, -1.9746e-02,\n",
              "        3.3024e-02, -1.2066e-02,  1.9534e-02, -1.7749e-02, -2.6609e-02,\n",
              "        5.0450e-02,  2.3968e-02, -1.8095e-02,  3.8698e-02, -7.7544e-02,\n",
              "        3.9485e-02, -5.6603e-02, -8.2745e-02, -6.2821e-02,  7.1270e-02,\n",
              "        5.3229e-02,  4.2347e-02,  1.1013e-01, -1.9416e-02,  4.0057e-02,\n",
              "        1.1877e-02,  2.1976e-02, -4.3974e-02, -3.9952e-02,  8.1423e-03,\n",
              "        3.5786e-02,  4.0291e-02, -3.0284e-02, -4.7791e-04,  9.1973e-02,\n",
              "       -2.0960e-02, -3.4431e-03, -2.1230e-02,  3.2893e-02, -1.3414e-03,\n",
              "        4.6214e-03,  1.3030e-02, -4.3791e-02,  6.3369e-02,  7.7385e-03,\n",
              "        7.9137e-04, -2.0740e-02, -5.8662e-02, -5.1212e-02,  2.3265e-03,\n",
              "        4.4197e-02,  3.5966e-02, -7.0367e-02, -2.8526e-03,  6.1232e-04,\n",
              "        1.9575e-03,  2.7297e-02, -2.2313e-02,  2.4786e-02, -6.0739e-03,\n",
              "        1.2645e-02, -4.2058e-02, -1.7790e-02,  6.0301e-02, -3.9324e-02,\n",
              "       -8.5582e-02,  1.3017e-02,  4.6979e-02, -1.7052e-02,  1.6901e-02,\n",
              "       -6.7735e-04,  3.6671e-02,  6.9531e-02, -1.9352e-02,  1.4261e-02,\n",
              "       -1.9591e-02, -5.7299e-02, -3.7458e-02, -4.3832e-02, -2.6229e-02,\n",
              "       -3.0012e-03, -1.4931e-02,  1.4623e-02,  5.3704e-02,  6.3559e-02,\n",
              "        5.5130e-03, -1.2413e-02, -1.0909e-01,  2.7417e-02,  1.0546e-01,\n",
              "       -1.3705e-02,  1.5796e-03, -7.7393e-03, -1.2479e-02,  1.6099e-02,\n",
              "        3.1006e-02,  3.1831e-02,  2.5892e-02,  4.4006e-02,  2.4637e-02,\n",
              "       -3.2499e-02, -2.7588e-03,  5.9954e-02, -1.8232e-02, -6.3606e-02,\n",
              "       -8.9740e-02, -2.9673e-02,  1.2605e-02,  3.4681e-02, -3.7524e-02,\n",
              "        3.2150e-02,  5.4579e-02, -5.1222e-03, -1.1554e-01, -4.1685e-02,\n",
              "        1.5409e-02,  6.0016e-02,  4.1625e-02, -1.4418e-02, -4.0570e-02,\n",
              "        2.9801e-02, -9.4080e-04, -4.8835e-02,  2.6504e-02,  1.1150e-02,\n",
              "       -6.0882e-03,  2.2073e-02, -2.4206e-02,  3.4350e-03,  3.7547e-02,\n",
              "        5.3624e-02,  4.1156e-03, -9.5203e-04, -4.4135e-02, -4.7512e-02,\n",
              "        2.1992e-02, -4.3255e-02,  1.7195e-02, -1.0009e-02,  7.5202e-02,\n",
              "       -3.2712e-02,  3.1156e-02, -1.1473e-02,  4.1999e-02, -2.2085e-02,\n",
              "       -9.6784e-03, -1.7582e-02,  7.1858e-02,  3.4948e-02, -8.3491e-02,\n",
              "       -4.5064e-02,  7.8194e-02, -2.0800e-02, -3.3462e-03, -1.2422e-02,\n",
              "        2.6670e-02, -1.9732e-02,  3.7980e-02, -2.6667e-02, -6.7573e-02,\n",
              "       -1.4641e-01,  1.0510e-01, -4.9850e-03, -5.5224e-02, -3.8239e-02,\n",
              "        3.2771e-02, -8.1752e-03,  3.7724e-02, -2.9128e-03, -3.3968e-02,\n",
              "        7.9673e-02, -1.1421e-02, -2.9329e-03, -1.9843e-02, -8.0257e-03,\n",
              "       -3.1226e-02,  1.4708e-02,  4.0941e-03,  1.4184e-02,  3.5069e-03,\n",
              "        2.1328e-02, -4.6866e-03, -3.0826e-02,  1.1640e-01, -1.9652e-02,\n",
              "        1.5016e-02,  6.6122e-03,  6.0226e-02,  5.5201e-02,  6.2925e-03,\n",
              "       -4.8688e-02, -1.3026e-01, -4.1683e-02,  3.7218e-02,  5.6448e-02,\n",
              "        5.5848e-03,  1.8628e-02, -4.5814e-03, -9.3255e-02,  2.6488e-02,\n",
              "        6.8315e-02,  3.2596e-02,  9.2062e-03, -1.6017e-02, -9.6877e-03,\n",
              "        1.8639e-02, -4.1959e-02, -1.4434e-02, -2.0775e-02,  4.3660e-02,\n",
              "        4.3450e-02,  3.4774e-03, -1.2793e-02, -2.6668e-02, -2.0136e-02,\n",
              "        6.3374e-03, -3.0162e-02,  6.6697e-02,  1.6978e-02,  3.4426e-03,\n",
              "        2.9116e-02,  3.3788e-02, -2.9641e-02, -4.5997e-02,  9.6274e-03,\n",
              "       -8.6986e-02, -7.7265e-02,  1.4431e-02,  1.2205e-02,  4.5300e-03,\n",
              "        5.4045e-02,  9.9330e-02, -8.1782e-02, -1.6955e-02,  1.7448e-02,\n",
              "       -2.3834e-02, -1.7435e-02,  2.0396e-02, -3.3258e-02,  6.0985e-02,\n",
              "        3.5481e-02, -1.2463e-02,  2.3011e-02, -3.1598e-03,  5.6196e-03,\n",
              "       -4.4726e-02,  1.1832e-03, -2.0341e-02, -8.2847e-04, -7.3357e-03,\n",
              "       -3.2539e-03,  2.2037e-02,  1.2812e-02,  1.5998e-02,  7.6569e-02,\n",
              "       -3.3195e-03, -6.5370e-02,  3.2078e-03, -6.5054e-02,  3.7316e-03],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# \"Project\" word embedding derieved by fasttext\n",
        "model_fasttext[\"project\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sE0BFc_pbR8G"
      },
      "outputs": [],
      "source": [
        "# Resume and position word embeddings by Word2Vec model (without context)\n",
        "w2v_resume = ncontext_word_embeddings(resume_tokens, position_tokens, model_w2v, 300)[0]\n",
        "w2v_position = ncontext_word_embeddings(resume_tokens, position_tokens, model_w2v, 300)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIgMxVscbR8L",
        "outputId": "b9a46b5e-a9c3-4a91-b4d4-5913f07aa320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Word2Vec cosine similarity: 0.8775057765303992\n",
            "Word2Vec sqrt-cos similarity: 0.5479819305240776\n",
            "Word2Vec improved sqrt-cos similarity: 0.9367527830385127\n"
          ]
        }
      ],
      "source": [
        "print(\"Word2Vec cosine similarity:\", cos_sim(w2v_resume, w2v_position))\n",
        "print(\"Word2Vec sqrt-cos similarity:\", sqrt_cos_sim(normalize_vector(w2v_resume), normalize_vector(w2v_position)))\n",
        "print(\"Word2Vec improved sqrt-cos similarity:\", improved_sqrt_cos_sim(w2v_resume, w2v_position))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U57bxlbfbR8L"
      },
      "outputs": [],
      "source": [
        "# Resume and position word embeddings by GloVe model (without context)\n",
        "glove_resume = ncontext_word_embeddings(resume_tokens, position_tokens, model_glove, 300)[0]\n",
        "glove_position = ncontext_word_embeddings(resume_tokens, position_tokens, model_glove, 300)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5br7niS2bR8L",
        "outputId": "e8192010-c856-4f0d-f922-0cdf3039b066"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GloVe cosine similarity: 0.9282224260373347\n",
            "GloVe sqrt-cos similarity: 0.9669506642601486\n",
            "GloVe improved sqrt-cos similarity: 0.9634430061178163\n"
          ]
        }
      ],
      "source": [
        "print(\"GloVe cosine similarity:\", cos_sim(glove_resume, glove_position))\n",
        "print(\"GloVe sqrt-cos similarity:\", sqrt_cos_sim(normalize_vector(glove_resume), normalize_vector(glove_position)))\n",
        "print(\"GloVe improved sqrt-cos similarity:\", improved_sqrt_cos_sim(glove_resume, glove_position))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tkB-sqPbR8L"
      },
      "outputs": [],
      "source": [
        "# Resume and position word embeddings by fasttext model (without context)\n",
        "fasttext_resume = ncontext_word_embeddings(resume_tokens, position_tokens, model_fasttext, 300)[0]\n",
        "fasttext_position = ncontext_word_embeddings(resume_tokens, position_tokens, model_fasttext, 300)[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uF-tACTjbR8M",
        "outputId": "b8b90ebb-e4fe-4c6c-b2b3-b8c69a5813a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fasttext cosine similarity: 0.9597905927359239\n",
            "fasttext sqrt-cos similarity: 0.920887663840816\n",
            "fasttext improved sqrt-cos similarity: 0.9796890285881147\n"
          ]
        }
      ],
      "source": [
        "print(\"fasttext cosine similarity:\", cos_sim(fasttext_resume, fasttext_position))\n",
        "print(\"fasttext sqrt-cos similarity:\", sqrt_cos_sim(normalize_vector(fasttext_resume), normalize_vector(fasttext_position)))\n",
        "print(\"fasttext improved sqrt-cos similarity:\", improved_sqrt_cos_sim(fasttext_resume, fasttext_position))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0IhB_dnbR8M"
      },
      "source": [
        "##### Section 2.3. Deep Learning models (with context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ9TS5EBbR8M"
      },
      "outputs": [],
      "source": [
        "# Build BERT model (with context)\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "bert_embeddings = context_word_embeddings_bert(\"bert-base-uncased\", corpus_resume, corpus_position, bert_tokenizer, bert_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rl39y7EbR8M"
      },
      "outputs": [],
      "source": [
        "# Resume and position word embeddings by BERT model (with context)\n",
        "bert_resume = tf.convert_to_tensor(bert_embeddings[0].numpy())\n",
        "bert_position = tf.convert_to_tensor(bert_embeddings[1].numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSohNfUKbR8M",
        "outputId": "189604cd-a030-415e-c9ad-c3e7a7bf304e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 768), dtype=float32, numpy=\n",
              "array([[-0.24948883,  0.23671284,  0.21300325, ..., -0.5167286 ,\n",
              "        -0.0167064 ,  0.40110615],\n",
              "       [-0.13348748,  0.50298893,  1.1789578 , ...,  0.11585795,\n",
              "         0.89747536, -0.50147355],\n",
              "       [ 0.3652598 ,  1.3704478 ,  0.76849085, ..., -0.15348034,\n",
              "         0.26663238, -0.07749266],\n",
              "       ...,\n",
              "       [-0.38198444,  0.37855992,  1.1884888 , ..., -0.09209996,\n",
              "         0.16719589,  0.6228476 ],\n",
              "       [-0.10712307,  0.3816907 ,  0.21916893, ..., -0.21529454,\n",
              "         0.04929146, -0.10734079],\n",
              "       [-0.22910808,  0.26557174,  0.8073412 , ...,  0.01077889,\n",
              "        -0.11126518,  0.36337057]], dtype=float32)>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ydYcZ0rbR8M",
        "outputId": "5426a0a0-0c31-4107-b1a0-fabc73a0b9e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 768), dtype=float32, numpy=\n",
              "array([[-0.32719356,  0.2911166 ,  0.0995127 , ..., -0.70458657,\n",
              "         0.10058991,  0.12757708],\n",
              "       [-0.09747656, -0.32714102,  0.8564409 , ...,  0.58886635,\n",
              "         0.62087536,  1.1605374 ],\n",
              "       [ 0.2581681 ,  0.05714206,  0.87274504, ..., -0.47108504,\n",
              "        -0.19724384, -0.45346382],\n",
              "       ...,\n",
              "       [-0.27867275,  0.08526617,  0.94428164, ..., -0.40449864,\n",
              "         0.08880097,  0.09942784],\n",
              "       [ 0.10933503,  0.32998013,  0.32587463, ..., -0.25213304,\n",
              "        -0.16210476, -0.29880297],\n",
              "       [-1.200947  , -0.5176007 ,  0.75854206, ..., -0.33721527,\n",
              "         0.00796723, -0.65257365]], dtype=float32)>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bert_position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BWABkgTbR8N",
        "outputId": "512a51d0-a617-496f-f063-2eb685f09678"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BERT cosine tensor similarity: 0.38806093\n",
            "BERT sqrt-cos tensor similarity: nan\n",
            "BERT improved sqrt-cos tensor similarity: 0.62294537\n"
          ]
        }
      ],
      "source": [
        "print(\"BERT cosine tensor similarity:\", cosine_similarity_tensorflow(bert_resume, bert_position).numpy())\n",
        "print(\"BERT sqrt-cos tensor similarity:\", sqrt_cos_sim_tensorflow(bert_resume, bert_position).numpy())\n",
        "print(\"BERT improved sqrt-cos tensor similarity:\", improved_sqrt_cos_sim_tensorflow(bert_resume, bert_position).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g4-bY8dUbR8N"
      },
      "outputs": [],
      "source": [
        "# Build ElMo model (with context)\n",
        "elmo_model = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
        "elmo_embeddings = context_word_embeddings_elmo(elmo_model, corpus_resume, corpus_position)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qttrxcE1bR8N"
      },
      "outputs": [],
      "source": [
        "# Resume and position word embeddings by ElMo model (with context)\n",
        "elmo_resume = elmo_embeddings[0]\n",
        "elmo_position = elmo_embeddings[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul0rELSrbR8N",
        "outputId": "6555a848-abe6-4af2-ad66-ed896cedcf9d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(402, 1024), dtype=float32, numpy=\n",
              "array([[ 0.96926683,  0.0197357 , -0.05022468, ..., -0.6011605 ,\n",
              "         0.04994965,  0.564479  ],\n",
              "       [ 0.6123357 ,  0.54600865,  0.39083087, ..., -0.6492162 ,\n",
              "         0.16072023, -0.4677832 ],\n",
              "       [ 0.443457  ,  0.4283167 ,  0.27562428, ..., -0.20470259,\n",
              "         0.0925293 , -0.32184893],\n",
              "       ...,\n",
              "       [-0.02840841, -0.04353216,  0.04130162, ...,  0.02583168,\n",
              "        -0.01429836, -0.01650422],\n",
              "       [-0.02840841, -0.04353216,  0.04130162, ...,  0.02583168,\n",
              "        -0.01429836, -0.01650422],\n",
              "       [-0.02840841, -0.04353216,  0.04130162, ...,  0.02583168,\n",
              "        -0.01429836, -0.01650422]], dtype=float32)>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elmo_resume"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC-bDRVvbR8N",
        "outputId": "f2d9d5a1-5c56-4578-c2d0-ddf12c88fb11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(402, 1024), dtype=float32, numpy=\n",
              "array([[ 0.0866392 , -0.04667937,  0.00528036, ..., -0.35448056,\n",
              "         0.26946062, -0.2253712 ],\n",
              "       [-0.39725125,  0.03733823,  0.06280055, ..., -0.93967694,\n",
              "         0.5207259 ,  0.75969124],\n",
              "       [-0.15930858,  0.29070768, -0.1728603 , ..., -0.14953661,\n",
              "         0.42402536, -0.6926011 ],\n",
              "       ...,\n",
              "       [-0.3457772 ,  0.12610844, -0.34094432, ...,  0.8936167 ,\n",
              "         0.55811393,  0.49377853],\n",
              "       [-0.34069228,  0.21508452, -0.49008286, ..., -0.19523671,\n",
              "        -0.10895094, -0.07450269],\n",
              "       [-0.40868595, -0.34031767, -0.54438156, ...,  0.15125084,\n",
              "         0.0727873 , -0.43524438]], dtype=float32)>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "elmo_position"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTD5sW3_bR8N",
        "outputId": "4a6da74a-3335-4ab1-9bfa-f9ec3b58ada0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ElMo cosine tensor similarity: 0.42995268\n",
            "ElMo sqrt-cos tensor similarity: nan\n",
            "ElMo improved sqrt-cos tensor similarity: 0.6557077\n"
          ]
        }
      ],
      "source": [
        "print(\"ElMo cosine tensor similarity:\", cosine_similarity_tensorflow(elmo_resume, elmo_position).numpy())\n",
        "print(\"ElMo sqrt-cos tensor similarity:\", sqrt_cos_sim_tensorflow(elmo_resume, elmo_position).numpy())\n",
        "print(\"ElMo improved sqrt-cos tensor similarity:\", improved_sqrt_cos_sim_tensorflow(elmo_resume, elmo_position).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUHtpg9hbR8N"
      },
      "source": [
        "### Section 3: Resume Selection Automation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Atn8kDVtbR8O",
        "outputId": "9532b055-2f42-494e-cc04-564773f3f086"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'Resume': 'Business analyst Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.06581740976645435,\n",
              "  'Dice similarity': 0.12350597609561753,\n",
              "  'Bag-of-words cosine similarity': 0.183583553976399,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.4284665144167032,\n",
              "  'Tf-idf cosine similarity': 0.11108178270708521,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.33328933782388726,\n",
              "  'Word2Vec cosine similarity': 0.8775057765303992,\n",
              "  'Word2Vec sqrt-cos similarity': 0.5479819305240776,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9367527830385127,\n",
              "  'GloVe cosine similarity': 0.9282224260373347,\n",
              "  'GloVe sqrt-cos similarity': 0.9669506642601486,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9634430061178163,\n",
              "  'FastText cosine similarity': 0.9597905927359239,\n",
              "  'FastText sqrt-cos similarity': 0.920887663840816,\n",
              "  'FastText improved sqrt-cos similarity': 0.9796890285881147,\n",
              "  'BERT cosine tensor similarity': 0.38806093,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.62294537,\n",
              "  'ElMo cosine tensor similarity': 0.42995268,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6557077},\n",
              " {'Resume': 'Business analyst Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.0650759219088937,\n",
              "  'Dice similarity': 0.12219959266802444,\n",
              "  'Bag-of-words cosine similarity': 0.1283321151316662,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.3582347207232518,\n",
              "  'Tf-idf cosine similarity': 0.07485766582325294,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.2736012898786352,\n",
              "  'Word2Vec cosine similarity': 0.8719680155621725,\n",
              "  'Word2Vec sqrt-cos similarity': 0.45667998514077357,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9337922764524091,\n",
              "  'GloVe cosine similarity': 0.9223976200584854,\n",
              "  'GloVe sqrt-cos similarity': 0.8990179105610946,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9604153372674165,\n",
              "  'FastText cosine similarity': 0.9572727029862229,\n",
              "  'FastText sqrt-cos similarity': 0.94057992863014,\n",
              "  'FastText improved sqrt-cos similarity': 0.9784031392969991,\n",
              "  'BERT cosine tensor similarity': 0.3132624,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.55969846,\n",
              "  'ElMo cosine tensor similarity': 0.4497454,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6706306},\n",
              " {'Resume': 'Junior Frontend Developer Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.05660377358490566,\n",
              "  'Dice similarity': 0.10714285714285714,\n",
              "  'Bag-of-words cosine similarity': 0.11630438090433073,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.3410342811277639,\n",
              "  'Tf-idf cosine similarity': 0.06411682822552243,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.25321300958979664,\n",
              "  'Word2Vec cosine similarity': 0.8549320551315723,\n",
              "  'Word2Vec sqrt-cos similarity': 0.2879257006632258,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9246253593383498,\n",
              "  'GloVe cosine similarity': 0.9270035463099975,\n",
              "  'GloVe sqrt-cos similarity': 0.9459496770022481,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9628102337999932,\n",
              "  'FastText cosine similarity': 0.9715148206256605,\n",
              "  'FastText sqrt-cos similarity': 0.91798751566266,\n",
              "  'FastText improved sqrt-cos similarity': 0.9856545138260467,\n",
              "  'BERT cosine tensor similarity': 0.33925098,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.58245254,\n",
              "  'ElMo cosine tensor similarity': 0.36678657,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6056291},\n",
              " {'Resume': 'Junior Frontend Developer Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.07641921397379912,\n",
              "  'Dice similarity': 0.14198782961460446,\n",
              "  'Bag-of-words cosine similarity': 0.17528491307045568,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.4186704110281209,\n",
              "  'Tf-idf cosine similarity': 0.10428281914330977,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.3229285046930818,\n",
              "  'Word2Vec cosine similarity': 0.8749220503595523,\n",
              "  'Word2Vec sqrt-cos similarity': 0.47963633250224835,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9353726799300652,\n",
              "  'GloVe cosine similarity': 0.9361097581660958,\n",
              "  'GloVe sqrt-cos similarity': 0.9545644889661195,\n",
              "  'GloVe improved sqrt-cos similarity': 0.967527652403845,\n",
              "  'FastText cosine similarity': 0.9746880428911374,\n",
              "  'FastText sqrt-cos similarity': 0.9479802078594387,\n",
              "  'FastText improved sqrt-cos similarity': 0.9872629046465472,\n",
              "  'BERT cosine tensor similarity': 0.30308393,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.55053055,\n",
              "  'ElMo cosine tensor similarity': 0.40645552,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6375387},\n",
              " {'Resume': 'Junior Full Stack Developer Female.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.03958333333333333,\n",
              "  'Dice similarity': 0.07615230460921844,\n",
              "  'Bag-of-words cosine similarity': 0.1097679970571395,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.3313125368245812,\n",
              "  'Tf-idf cosine similarity': 0.06076659967554584,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.24650882271339872,\n",
              "  'Word2Vec cosine similarity': 0.8218506362436884,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9065597808438716,\n",
              "  'GloVe cosine similarity': 0.9027193816228501,\n",
              "  'GloVe sqrt-cos similarity': 0.9453142586240245,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9501154569960695,\n",
              "  'FastText cosine similarity': 0.8905469737268712,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9436879641740014,\n",
              "  'BERT cosine tensor similarity': 0.36020565,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.6001714,\n",
              "  'ElMo cosine tensor similarity': 0.36774263,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.60641783},\n",
              " {'Resume': 'Junior Full Stack Developer Female.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.07017543859649122,\n",
              "  'Dice similarity': 0.13114754098360656,\n",
              "  'Bag-of-words cosine similarity': 0.20590958016608102,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.4537726084351951,\n",
              "  'Tf-idf cosine similarity': 0.12043183657872283,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.3470329041729658,\n",
              "  'Word2Vec cosine similarity': 0.836265867547877,\n",
              "  'Word2Vec sqrt-cos similarity': 0.3399642793603916,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9144757337118777,\n",
              "  'GloVe cosine similarity': 0.9114742628104001,\n",
              "  'GloVe sqrt-cos similarity': 0.9416834662608068,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9547116123785234,\n",
              "  'FastText cosine similarity': 0.894367961678344,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9457102947934658,\n",
              "  'BERT cosine tensor similarity': 0.30182275,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.549384,\n",
              "  'ElMo cosine tensor similarity': 0.41638964,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.64528257},\n",
              " {'Resume': 'Junior Software Developer Female.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.04358974358974359,\n",
              "  'Dice similarity': 0.08353808353808354,\n",
              "  'Bag-of-words cosine similarity': 0.13363256896704281,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.36555788729973093,\n",
              "  'Tf-idf cosine similarity': 0.07752383502565763,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.2784310238203668,\n",
              "  'Word2Vec cosine similarity': 0.7428643426393201,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8618957840941792,\n",
              "  'GloVe cosine similarity': 0.8020343921946462,\n",
              "  'GloVe sqrt-cos similarity': 0.8885850896777069,\n",
              "  'GloVe improved sqrt-cos similarity': 0.895563728717642,\n",
              "  'FastText cosine similarity': 0.8631434625683526,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9290551450631724,\n",
              "  'BERT cosine tensor similarity': 0.24698955,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.49698043,\n",
              "  'ElMo cosine tensor similarity': 0.22992261,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.47950244},\n",
              " {'Resume': 'Junior Software Developer Female.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.07027027027027027,\n",
              "  'Dice similarity': 0.13131313131313133,\n",
              "  'Bag-of-words cosine similarity': 0.1550964517315579,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.39382286847205544,\n",
              "  'Tf-idf cosine similarity': 0.09053680638976006,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.3008933472008979,\n",
              "  'Word2Vec cosine similarity': 0.7309320379822238,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8549456345184901,\n",
              "  'GloVe cosine similarity': 0.7884226967622251,\n",
              "  'GloVe sqrt-cos similarity': 0.848442022529456,\n",
              "  'GloVe improved sqrt-cos similarity': 0.8879316960004441,\n",
              "  'FastText cosine similarity': 0.8605570500390676,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9276621421827387,\n",
              "  'BERT cosine tensor similarity': 0.32909697,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.57366973,\n",
              "  'ElMo cosine tensor similarity': 0.2899758,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.53849405},\n",
              " {'Resume': 'Middle .NET Developer Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.002932551319648094,\n",
              "  'Dice similarity': 0.005847953216374269,\n",
              "  'Bag-of-words cosine similarity': 0.0,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.0,\n",
              "  'Tf-idf cosine similarity': 0.0,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.0,\n",
              "  'Word2Vec cosine similarity': 0.2208299956978637,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.46992552143702915,\n",
              "  'GloVe cosine similarity': 0.2892411411932624,\n",
              "  'GloVe sqrt-cos similarity': nan,\n",
              "  'GloVe improved sqrt-cos similarity': 0.5378114364656653,\n",
              "  'FastText cosine similarity': -0.11332272444979895,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': nan,\n",
              "  'BERT cosine tensor similarity': 0.28695285,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.53567976,\n",
              "  'ElMo cosine tensor similarity': 0.109714255,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.33123142},\n",
              " {'Resume': 'Middle .NET Developer Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.0030303030303030303,\n",
              "  'Dice similarity': 0.006042296072507553,\n",
              "  'Bag-of-words cosine similarity': 0.0,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.0,\n",
              "  'Tf-idf cosine similarity': 0.0,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.0,\n",
              "  'Word2Vec cosine similarity': 0.20922444608388666,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.4574105880758409,\n",
              "  'GloVe cosine similarity': 0.300363581952231,\n",
              "  'GloVe sqrt-cos similarity': nan,\n",
              "  'GloVe improved sqrt-cos similarity': 0.5480543603988851,\n",
              "  'FastText cosine similarity': -0.10637634933004216,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': nan,\n",
              "  'BERT cosine tensor similarity': 0.28286722,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.5318526,\n",
              "  'ElMo cosine tensor similarity': 0.14184032,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.37661693},\n",
              " {'Resume': 'Middle Java Engineer Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.05121951219512195,\n",
              "  'Dice similarity': 0.09744779582366589,\n",
              "  'Bag-of-words cosine similarity': 0.1132529138668492,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.336530702710539,\n",
              "  'Tf-idf cosine similarity': 0.06409775891448001,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.2531753521069538,\n",
              "  'Word2Vec cosine similarity': 0.7775319943801148,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8817777465893064,\n",
              "  'GloVe cosine similarity': 0.884035851727921,\n",
              "  'GloVe sqrt-cos similarity': 0.9312807049891618,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9402318074432076,\n",
              "  'FastText cosine similarity': 0.907036853364027,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9523848241987202,\n",
              "  'BERT cosine tensor similarity': 0.3133215,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.55975133,\n",
              "  'ElMo cosine tensor similarity': 0.27603874,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.52539384},\n",
              " {'Resume': 'Middle Java Engineer Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.06329113924050633,\n",
              "  'Dice similarity': 0.11904761904761904,\n",
              "  'Bag-of-words cosine similarity': 0.16357406358309817,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.4044429052203761,\n",
              "  'Tf-idf cosine similarity': 0.09655402477294517,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.31073143512194773,\n",
              "  'Word2Vec cosine similarity': 0.7809223406087658,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8836981049027806,\n",
              "  'GloVe cosine similarity': 0.8931663892576438,\n",
              "  'GloVe sqrt-cos similarity': 0.9058035304745506,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9450748061702013,\n",
              "  'FastText cosine similarity': 0.9066865305898637,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.952200887727933,\n",
              "  'BERT cosine tensor similarity': 0.26508647,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.51486546,\n",
              "  'ElMo cosine tensor similarity': 0.34924227,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.5909672},\n",
              " {'Resume': 'Product Marketing Manager Female.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.05343511450381679,\n",
              "  'Dice similarity': 0.10144927536231885,\n",
              "  'Bag-of-words cosine similarity': 0.09822676572627814,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.31341149584257133,\n",
              "  'Tf-idf cosine similarity': 0.05423864302009264,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.23289191274085205,\n",
              "  'Word2Vec cosine similarity': 0.7820473857404113,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8843344309368552,\n",
              "  'GloVe cosine similarity': 0.8291468760761289,\n",
              "  'GloVe sqrt-cos similarity': 0.8446618694115987,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9105750249573775,\n",
              "  'FastText cosine similarity': 0.9232697052101602,\n",
              "  'FastText sqrt-cos similarity': 0.9227530942577591,\n",
              "  'FastText improved sqrt-cos similarity': 0.9608692445958295,\n",
              "  'BERT cosine tensor similarity': 0.33494166,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.57874143,\n",
              "  'ElMo cosine tensor similarity': 0.34869918,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.5905075},\n",
              " {'Resume': 'Product Marketing Manager Female.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.05221932114882506,\n",
              "  'Dice similarity': 0.09925558312655088,\n",
              "  'Bag-of-words cosine similarity': 0.10983593473570433,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.3314150490483259,\n",
              "  'Tf-idf cosine similarity': 0.06099547025538378,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.24697261033439274,\n",
              "  'Word2Vec cosine similarity': 0.7469312220854737,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8642518279329664,\n",
              "  'GloVe cosine similarity': 0.8014350259370275,\n",
              "  'GloVe sqrt-cos similarity': 0.8728697879564777,\n",
              "  'GloVe improved sqrt-cos similarity': 0.8952290354635664,\n",
              "  'FastText cosine similarity': 0.9148728628819429,\n",
              "  'FastText sqrt-cos similarity': 0.9097598881480516,\n",
              "  'FastText improved sqrt-cos similarity': 0.9564898655406354,\n",
              "  'BERT cosine tensor similarity': 0.28483403,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.5336984,\n",
              "  'ElMo cosine tensor similarity': 0.3808222,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6171079},\n",
              " {'Resume': 'QA Specialist Female.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.0368763557483731,\n",
              "  'Dice similarity': 0.07112970711297072,\n",
              "  'Bag-of-words cosine similarity': 0.07119438829340988,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.2668227656955266,\n",
              "  'Tf-idf cosine similarity': 0.03804402457391933,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.19504877485880126,\n",
              "  'Word2Vec cosine similarity': 0.7765559341876379,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8812241112155511,\n",
              "  'GloVe cosine similarity': 0.8873706342428312,\n",
              "  'GloVe sqrt-cos similarity': 0.8882231933616644,\n",
              "  'GloVe improved sqrt-cos similarity': 0.942003521353732,\n",
              "  'FastText cosine similarity': 0.8564085199164382,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9254234273652456,\n",
              "  'BERT cosine tensor similarity': 0.37528402,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.6126043,\n",
              "  'ElMo cosine tensor similarity': 0.3347464,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.57857275},\n",
              " {'Resume': 'QA Specialist Female.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.06621004566210045,\n",
              "  'Dice similarity': 0.12419700214132762,\n",
              "  'Bag-of-words cosine similarity': 0.16053738189177763,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.40067116428784544,\n",
              "  'Tf-idf cosine similarity': 0.09441171481703937,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.3072648935642329,\n",
              "  'Word2Vec cosine similarity': 0.7780407626946688,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8820661895201906,\n",
              "  'GloVe cosine similarity': 0.8943839587038411,\n",
              "  'GloVe sqrt-cos similarity': 0.962151335731113,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9457187524332172,\n",
              "  'FastText cosine similarity': 0.8576021320900469,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9260681033757976,\n",
              "  'BERT cosine tensor similarity': 0.2863739,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.53513914,\n",
              "  'ElMo cosine tensor similarity': 0.38853097,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.62332255},\n",
              " {'Resume': 'Senior .NET Developer Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.0449438202247191,\n",
              "  'Dice similarity': 0.08602150537634409,\n",
              "  'Bag-of-words cosine similarity': 0.13734396382417605,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.37059946549364586,\n",
              "  'Tf-idf cosine similarity': 0.07754647281855677,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.2784716732785523,\n",
              "  'Word2Vec cosine similarity': 0.8671104288458682,\n",
              "  'Word2Vec sqrt-cos similarity': 0.5684033077387228,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.931187644272554,\n",
              "  'GloVe cosine similarity': 0.9228425165846396,\n",
              "  'GloVe sqrt-cos similarity': 0.9669640341297054,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9606469260787958,\n",
              "  'FastText cosine similarity': 0.9491525066968638,\n",
              "  'FastText sqrt-cos similarity': 0.5116343020239725,\n",
              "  'FastText improved sqrt-cos similarity': 0.97424458258533,\n",
              "  'BERT cosine tensor similarity': 0.35304967,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.5941798,\n",
              "  'ElMo cosine tensor similarity': 0.3057083,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.5529089},\n",
              " {'Resume': 'Senior .NET Developer Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.07582938388625593,\n",
              "  'Dice similarity': 0.14096916299559473,\n",
              "  'Bag-of-words cosine similarity': 0.21944612627696977,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.4684507725225456,\n",
              "  'Tf-idf cosine similarity': 0.13079657738146733,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.36165809458861464,\n",
              "  'Word2Vec cosine similarity': 0.8729926268073097,\n",
              "  'Word2Vec sqrt-cos similarity': 0.28430786944822045,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9343407444863516,\n",
              "  'GloVe cosine similarity': 0.9315179607704798,\n",
              "  'GloVe sqrt-cos similarity': 0.9253752933112427,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9651517812087795,\n",
              "  'FastText cosine similarity': 0.9498962103875431,\n",
              "  'FastText sqrt-cos similarity': 0.6339546809490385,\n",
              "  'FastText improved sqrt-cos similarity': 0.9746261900788132,\n",
              "  'BERT cosine tensor similarity': 0.27564305,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.52501714,\n",
              "  'ElMo cosine tensor similarity': 0.36512512,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.60425586},\n",
              " {'Resume': 'Senior Electrical Engineer Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.061224489795918366,\n",
              "  'Dice similarity': 0.11538461538461539,\n",
              "  'Bag-of-words cosine similarity': 0.0899961456206771,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.29999357596568144,\n",
              "  'Tf-idf cosine similarity': 0.051180948199546175,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.22623206713360988,\n",
              "  'Word2Vec cosine similarity': 0.7874315074360884,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8873733754379203,\n",
              "  'GloVe cosine similarity': 0.8641164998987256,\n",
              "  'GloVe sqrt-cos similarity': 0.9272291181579935,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9295786679451749,\n",
              "  'FastText cosine similarity': 0.8707980195130001,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9331655906177639,\n",
              "  'BERT cosine tensor similarity': 0.3450977,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.58745015,\n",
              "  'ElMo cosine tensor similarity': 0.41749072,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.64613515},\n",
              " {'Resume': 'Senior Electrical Engineer Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.07383966244725738,\n",
              "  'Dice similarity': 0.137524557956778,\n",
              "  'Bag-of-words cosine similarity': 0.1938802142168069,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.440318310108502,\n",
              "  'Tf-idf cosine similarity': 0.11332269042601688,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.33663435716815493,\n",
              "  'Word2Vec cosine similarity': 0.7901564165152679,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8889074285409406,\n",
              "  'GloVe cosine similarity': 0.8719199768681971,\n",
              "  'GloVe sqrt-cos similarity': 0.8743428547114405,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9337665537318185,\n",
              "  'FastText cosine similarity': 0.8675503554912348,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9314238323616348,\n",
              "  'BERT cosine tensor similarity': 0.30193028,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.54948187,\n",
              "  'ElMo cosine tensor similarity': 0.42744192,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6537904},\n",
              " {'Resume': 'Senior Software Engineer Male.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.07311320754716981,\n",
              "  'Dice similarity': 0.13626373626373625,\n",
              "  'Bag-of-words cosine similarity': 0.15531282252912765,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.39409747846075793,\n",
              "  'Tf-idf cosine similarity': 0.09155540017187563,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.3025812290474669,\n",
              "  'Word2Vec cosine similarity': 0.8136107213772654,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9020037258111883,\n",
              "  'GloVe cosine similarity': 0.8809465774237166,\n",
              "  'GloVe sqrt-cos similarity': 0.8555836244010899,\n",
              "  'GloVe improved sqrt-cos similarity': 0.938587543825144,\n",
              "  'FastText cosine similarity': 0.9350426659079357,\n",
              "  'FastText sqrt-cos similarity': 0.7651206064641736,\n",
              "  'FastText improved sqrt-cos similarity': 0.966976042054784,\n",
              "  'BERT cosine tensor similarity': 0.3496677,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.59132713,\n",
              "  'ElMo cosine tensor similarity': 0.32242477,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.5678246},\n",
              " {'Resume': 'Senior Software Engineer Male.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.10173697270471464,\n",
              "  'Dice similarity': 0.18468468468468469,\n",
              "  'Bag-of-words cosine similarity': 0.2546360780915496,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.504614781879752,\n",
              "  'Tf-idf cosine similarity': 0.15857287164481446,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.398212093795272,\n",
              "  'Word2Vec cosine similarity': 0.8193561402704613,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.9051829319372195,\n",
              "  'GloVe cosine similarity': 0.8955503739541207,\n",
              "  'GloVe sqrt-cos similarity': 0.9518940288418054,\n",
              "  'GloVe improved sqrt-cos similarity': 0.9463352333893739,\n",
              "  'FastText cosine similarity': 0.9352426363600377,\n",
              "  'FastText sqrt-cos similarity': 0.822508202512545,\n",
              "  'FastText improved sqrt-cos similarity': 0.9670794364270382,\n",
              "  'BERT cosine tensor similarity': 0.28681678,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.53555274,\n",
              "  'ElMo cosine tensor similarity': 0.39101666,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.6253132},\n",
              " {'Resume': 'Trainee UX-UI Designer Female.pdf',\n",
              "  'Position': 'Business Analyst.txt',\n",
              "  'Jaccard similarity': 0.021341463414634148,\n",
              "  'Dice similarity': 0.041791044776119404,\n",
              "  'Bag-of-words cosine similarity': 0.12331960465709783,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.35116891186022975,\n",
              "  'Tf-idf cosine similarity': 0.06827721468370555,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.261299090476231,\n",
              "  'Word2Vec cosine similarity': 0.6685962965620446,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8176773792652239,\n",
              "  'GloVe cosine similarity': 0.7616856215926012,\n",
              "  'GloVe sqrt-cos similarity': 0.8096117202987304,\n",
              "  'GloVe improved sqrt-cos similarity': 0.8727460235329642,\n",
              "  'FastText cosine similarity': 0.8579197264695556,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9262395621379792,\n",
              "  'BERT cosine tensor similarity': 0.303523,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.55092925,\n",
              "  'ElMo cosine tensor similarity': 0.11840489,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.34410012},\n",
              " {'Resume': 'Trainee UX-UI Designer Female.pdf',\n",
              "  'Position': 'Senior Software Developer.txt',\n",
              "  'Jaccard similarity': 0.03514376996805112,\n",
              "  'Dice similarity': 0.06790123456790123,\n",
              "  'Bag-of-words cosine similarity': 0.17680398196737077,\n",
              "  'Bag-of-words sqrt-cos similarity': nan,\n",
              "  'Bag-of-words improved sqrt-cos similarity': 0.4204806558777357,\n",
              "  'Tf-idf cosine similarity': 0.10175590848572398,\n",
              "  'Tf-idf sqrt-cos similarity': nan,\n",
              "  'Tf-idf improved sqrt-cos similarity': 0.3189920194702745,\n",
              "  'Word2Vec cosine similarity': 0.7030588247194096,\n",
              "  'Word2Vec sqrt-cos similarity': nan,\n",
              "  'Word2Vec improved sqrt-cos similarity': 0.8384860313203849,\n",
              "  'GloVe cosine similarity': 0.7800268481585281,\n",
              "  'GloVe sqrt-cos similarity': 0.8371094009517221,\n",
              "  'GloVe improved sqrt-cos similarity': 0.8831912862786453,\n",
              "  'FastText cosine similarity': 0.865121621875122,\n",
              "  'FastText sqrt-cos similarity': nan,\n",
              "  'FastText improved sqrt-cos similarity': 0.9301191439138978,\n",
              "  'BERT cosine tensor similarity': 0.25887907,\n",
              "  'BERT sqrt-cos tensor similarity': nan,\n",
              "  'BERT improved sqrt-cos tensor similarity': 0.5088016,\n",
              "  'ElMo cosine tensor similarity': 0.16460328,\n",
              "  'ElMo sqrt-cos tensor similarity': nan,\n",
              "  'ElMo improved sqrt-cos tensor similarity': 0.4057133}]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build Deep Learning models\n",
        "model_w2v = build_model_ncontext(model_path=\"word2vec-google-news-300.model\")\n",
        "model_glove = build_model_ncontext(model_path=\"glove-wiki-gigaword-300.model\")\n",
        "model_fasttext = build_model_ncontext(model_path=\"fasttext-wiki-news-subwords-300.model\")\n",
        "\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "bert_model = BertModel.from_pretrained(\"bert-base-uncased\", output_hidden_states=True)\n",
        "elmo_model = hub.load(\"https://tfhub.dev/google/elmo/3\")\n",
        "\n",
        "# Define list of resumes and positions\n",
        "resume_list = [\"Business analyst Male.pdf\", \"Junior Frontend Developer Male.pdf\", \"Junior Full Stack Developer Female.pdf\",\n",
        "               \"Junior Software Developer Female.pdf\", \"Middle .NET Developer Male.pdf\", \"Middle Java Engineer Male.pdf\",\n",
        "               \"Product Marketing Manager Female.pdf\", \"QA Specialist Female.pdf\", \"Senior .NET Developer Male.pdf\",\n",
        "               \"Senior Electrical Engineer Male.pdf\", \"Senior Software Engineer Male.pdf\", \"Trainee UX-UI Designer Female.pdf\"]\n",
        "position_list = [\"Business Analyst.txt\", \"Senior Software Developer.txt\"]\n",
        "\n",
        "# Initialize an empty list to store the results\n",
        "results = []\n",
        "\n",
        "# Iterate over all combinations of resumes and positions\n",
        "for resume, position in product(resume_list, position_list):\n",
        "    # Read and preprocess resume and position\n",
        "    resume_text = read_resume(resume)\n",
        "    position_text = read_position(position)\n",
        "    resume_text = tokenize_description(resume_text)\n",
        "    position_text = tokenize_description(position_text)\n",
        "    resume_text = [preprocessing_text(sentence) for sentence in resume_text]\n",
        "    position_text = [preprocessing_text(sentence) for sentence in position_text]\n",
        "    position_tokens = [word_tokenize(sentence) for sentence in position_text]\n",
        "    resume_tokens = [word_tokenize(sentence) for sentence in resume_text]\n",
        "    flatten_position_tokens = sum(position_tokens, [])\n",
        "    flatten_resume_tokens = sum(resume_tokens, [])\n",
        "    corpus_resume = create_corpus(resume_text)\n",
        "    corpus_position = create_corpus(position_text)\n",
        "\n",
        "    # Calculate and store characteristics\n",
        "    characteristics = {}\n",
        "\n",
        "    characteristics['Resume'] = resume\n",
        "    characteristics['Position'] = position\n",
        "    characteristics['Jaccard similarity'] = jaccard_sim(flatten_resume_tokens, flatten_position_tokens)\n",
        "    characteristics['Dice similarity'] = dice_sim(flatten_resume_tokens, flatten_position_tokens)\n",
        "\n",
        "    bow_resume = bag_of_words(corpus_resume, corpus_position)[1]\n",
        "    bow_position = bag_of_words(corpus_resume, corpus_position)[2]\n",
        "    characteristics['Bag-of-words cosine similarity'] = cos_sim(bow_resume, bow_position)\n",
        "    characteristics['Bag-of-words sqrt-cos similarity'] = sqrt_cos_sim(normalize_vector(bow_resume), normalize_vector(bow_position))\n",
        "    characteristics['Bag-of-words improved sqrt-cos similarity'] = improved_sqrt_cos_sim(bow_resume, bow_position)\n",
        "\n",
        "    tf_idf_resume = tf_idf(corpus_resume, corpus_position)[1]\n",
        "    tf_idf_position = tf_idf(corpus_resume, corpus_position)[2]\n",
        "    characteristics['Tf-idf cosine similarity'] = cos_sim(tf_idf_resume, tf_idf_position)\n",
        "    characteristics['Tf-idf sqrt-cos similarity'] = sqrt_cos_sim(normalize_vector(tf_idf_resume), normalize_vector(tf_idf_position))\n",
        "    characteristics['Tf-idf improved sqrt-cos similarity'] = improved_sqrt_cos_sim(tf_idf_resume, tf_idf_position)\n",
        "\n",
        "    for model_name, model in [(\"Word2Vec\", model_w2v), (\"GloVe\", model_glove), (\"FastText\", model_fasttext)]:\n",
        "        embeddings_resume = ncontext_word_embeddings(resume_tokens, position_tokens, model, 300)[0]\n",
        "        embeddings_position = ncontext_word_embeddings(resume_tokens, position_tokens, model, 300)[1]\n",
        "        characteristics[f\"{model_name} cosine similarity\"] = cos_sim(embeddings_resume, embeddings_position)\n",
        "        characteristics[f\"{model_name} sqrt-cos similarity\"] = sqrt_cos_sim(normalize_vector(embeddings_resume), normalize_vector(embeddings_position))\n",
        "        characteristics[f\"{model_name} improved sqrt-cos similarity\"] = improved_sqrt_cos_sim(embeddings_resume, embeddings_position)\n",
        "\n",
        "    bert_embeddings = context_word_embeddings_bert(\"bert-base-uncased\", corpus_resume, corpus_position, bert_tokenizer, bert_model)\n",
        "    bert_resume = tf.convert_to_tensor(bert_embeddings[0].numpy())\n",
        "    bert_position = tf.convert_to_tensor(bert_embeddings[1].numpy())\n",
        "    characteristics['BERT cosine tensor similarity'] = cosine_similarity_tensorflow(bert_resume, bert_position).numpy()\n",
        "    characteristics['BERT sqrt-cos tensor similarity'] = sqrt_cos_sim_tensorflow(bert_resume, bert_position).numpy()\n",
        "    characteristics['BERT improved sqrt-cos tensor similarity'] = improved_sqrt_cos_sim_tensorflow(bert_resume, bert_position).numpy()\n",
        "\n",
        "    elmo_embeddings = context_word_embeddings_elmo(elmo_model, corpus_resume, corpus_position)\n",
        "    elmo_resume = elmo_embeddings[0]\n",
        "    elmo_position = elmo_embeddings[1]\n",
        "    characteristics['ElMo cosine tensor similarity'] = cosine_similarity_tensorflow(elmo_resume, elmo_position).numpy()\n",
        "    characteristics['ElMo sqrt-cos tensor similarity'] = sqrt_cos_sim_tensorflow(elmo_resume, elmo_position).numpy()\n",
        "    characteristics['ElMo improved sqrt-cos tensor similarity'] = improved_sqrt_cos_sim_tensorflow(elmo_resume, elmo_position).numpy()\n",
        "\n",
        "    results.append(characteristics)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30MFq-cfbR8O",
        "outputId": "594d0da0-2d7d-47be-b3c7-eda460d76500"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Resume</th>\n",
              "      <th>Position</th>\n",
              "      <th>Jaccard similarity</th>\n",
              "      <th>Dice similarity</th>\n",
              "      <th>Bag-of-words cosine similarity</th>\n",
              "      <th>Bag-of-words sqrt-cos similarity</th>\n",
              "      <th>Bag-of-words improved sqrt-cos similarity</th>\n",
              "      <th>Tf-idf cosine similarity</th>\n",
              "      <th>Tf-idf sqrt-cos similarity</th>\n",
              "      <th>Tf-idf improved sqrt-cos similarity</th>\n",
              "      <th>...</th>\n",
              "      <th>GloVe improved sqrt-cos similarity</th>\n",
              "      <th>FastText cosine similarity</th>\n",
              "      <th>FastText sqrt-cos similarity</th>\n",
              "      <th>FastText improved sqrt-cos similarity</th>\n",
              "      <th>BERT cosine tensor similarity</th>\n",
              "      <th>BERT sqrt-cos tensor similarity</th>\n",
              "      <th>BERT improved sqrt-cos tensor similarity</th>\n",
              "      <th>ElMo cosine tensor similarity</th>\n",
              "      <th>ElMo sqrt-cos tensor similarity</th>\n",
              "      <th>ElMo improved sqrt-cos tensor similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Business analyst Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.065817</td>\n",
              "      <td>0.123506</td>\n",
              "      <td>0.183584</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.428467</td>\n",
              "      <td>0.111082</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.333289</td>\n",
              "      <td>...</td>\n",
              "      <td>0.963443</td>\n",
              "      <td>0.959791</td>\n",
              "      <td>0.920888</td>\n",
              "      <td>0.979689</td>\n",
              "      <td>0.388061</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.622945</td>\n",
              "      <td>0.429953</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.655708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Business analyst Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.065076</td>\n",
              "      <td>0.122200</td>\n",
              "      <td>0.128332</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.358235</td>\n",
              "      <td>0.074858</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.273601</td>\n",
              "      <td>...</td>\n",
              "      <td>0.960415</td>\n",
              "      <td>0.957273</td>\n",
              "      <td>0.940580</td>\n",
              "      <td>0.978403</td>\n",
              "      <td>0.313262</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.559698</td>\n",
              "      <td>0.449745</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.670631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Junior Frontend Developer Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.056604</td>\n",
              "      <td>0.107143</td>\n",
              "      <td>0.116304</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.341034</td>\n",
              "      <td>0.064117</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.253213</td>\n",
              "      <td>...</td>\n",
              "      <td>0.962810</td>\n",
              "      <td>0.971515</td>\n",
              "      <td>0.917988</td>\n",
              "      <td>0.985655</td>\n",
              "      <td>0.339251</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.582453</td>\n",
              "      <td>0.366787</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.605629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Junior Frontend Developer Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.076419</td>\n",
              "      <td>0.141988</td>\n",
              "      <td>0.175285</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.418670</td>\n",
              "      <td>0.104283</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.322929</td>\n",
              "      <td>...</td>\n",
              "      <td>0.967528</td>\n",
              "      <td>0.974688</td>\n",
              "      <td>0.947980</td>\n",
              "      <td>0.987263</td>\n",
              "      <td>0.303084</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.550531</td>\n",
              "      <td>0.406456</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.637539</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Junior Full Stack Developer Female.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.039583</td>\n",
              "      <td>0.076152</td>\n",
              "      <td>0.109768</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.331313</td>\n",
              "      <td>0.060767</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.246509</td>\n",
              "      <td>...</td>\n",
              "      <td>0.950115</td>\n",
              "      <td>0.890547</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.943688</td>\n",
              "      <td>0.360206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.600171</td>\n",
              "      <td>0.367743</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.606418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Junior Full Stack Developer Female.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.070175</td>\n",
              "      <td>0.131148</td>\n",
              "      <td>0.205910</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.453773</td>\n",
              "      <td>0.120432</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.347033</td>\n",
              "      <td>...</td>\n",
              "      <td>0.954712</td>\n",
              "      <td>0.894368</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.945710</td>\n",
              "      <td>0.301823</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.549384</td>\n",
              "      <td>0.416390</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.645283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Junior Software Developer Female.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.043590</td>\n",
              "      <td>0.083538</td>\n",
              "      <td>0.133633</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.365558</td>\n",
              "      <td>0.077524</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895564</td>\n",
              "      <td>0.863143</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.929055</td>\n",
              "      <td>0.246990</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.496980</td>\n",
              "      <td>0.229923</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.479502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Junior Software Developer Female.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.070270</td>\n",
              "      <td>0.131313</td>\n",
              "      <td>0.155096</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.393823</td>\n",
              "      <td>0.090537</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.300893</td>\n",
              "      <td>...</td>\n",
              "      <td>0.887932</td>\n",
              "      <td>0.860557</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.927662</td>\n",
              "      <td>0.329097</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.573670</td>\n",
              "      <td>0.289976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.538494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Middle .NET Developer Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.002933</td>\n",
              "      <td>0.005848</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.537811</td>\n",
              "      <td>-0.113323</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.286953</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.535680</td>\n",
              "      <td>0.109714</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.331231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Middle .NET Developer Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.003030</td>\n",
              "      <td>0.006042</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.548054</td>\n",
              "      <td>-0.106376</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.282867</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.531853</td>\n",
              "      <td>0.141840</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.376617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Middle Java Engineer Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.051220</td>\n",
              "      <td>0.097448</td>\n",
              "      <td>0.113253</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.336531</td>\n",
              "      <td>0.064098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.253175</td>\n",
              "      <td>...</td>\n",
              "      <td>0.940232</td>\n",
              "      <td>0.907037</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.952385</td>\n",
              "      <td>0.313322</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.559751</td>\n",
              "      <td>0.276039</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.525394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Middle Java Engineer Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.063291</td>\n",
              "      <td>0.119048</td>\n",
              "      <td>0.163574</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.404443</td>\n",
              "      <td>0.096554</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.310731</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945075</td>\n",
              "      <td>0.906687</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.952201</td>\n",
              "      <td>0.265086</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.514865</td>\n",
              "      <td>0.349242</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.590967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Product Marketing Manager Female.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.053435</td>\n",
              "      <td>0.101449</td>\n",
              "      <td>0.098227</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.313411</td>\n",
              "      <td>0.054239</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.232892</td>\n",
              "      <td>...</td>\n",
              "      <td>0.910575</td>\n",
              "      <td>0.923270</td>\n",
              "      <td>0.922753</td>\n",
              "      <td>0.960869</td>\n",
              "      <td>0.334942</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.578741</td>\n",
              "      <td>0.348699</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.590508</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Product Marketing Manager Female.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.052219</td>\n",
              "      <td>0.099256</td>\n",
              "      <td>0.109836</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.331415</td>\n",
              "      <td>0.060995</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.246973</td>\n",
              "      <td>...</td>\n",
              "      <td>0.895229</td>\n",
              "      <td>0.914873</td>\n",
              "      <td>0.909760</td>\n",
              "      <td>0.956490</td>\n",
              "      <td>0.284834</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.533698</td>\n",
              "      <td>0.380822</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.617108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>QA Specialist Female.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.036876</td>\n",
              "      <td>0.071130</td>\n",
              "      <td>0.071194</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.266823</td>\n",
              "      <td>0.038044</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.195049</td>\n",
              "      <td>...</td>\n",
              "      <td>0.942004</td>\n",
              "      <td>0.856409</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.925423</td>\n",
              "      <td>0.375284</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.612604</td>\n",
              "      <td>0.334746</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.578573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>QA Specialist Female.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.066210</td>\n",
              "      <td>0.124197</td>\n",
              "      <td>0.160537</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.400671</td>\n",
              "      <td>0.094412</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.307265</td>\n",
              "      <td>...</td>\n",
              "      <td>0.945719</td>\n",
              "      <td>0.857602</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.926068</td>\n",
              "      <td>0.286374</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.535139</td>\n",
              "      <td>0.388531</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.623323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Senior .NET Developer Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.044944</td>\n",
              "      <td>0.086022</td>\n",
              "      <td>0.137344</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.370599</td>\n",
              "      <td>0.077546</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.278472</td>\n",
              "      <td>...</td>\n",
              "      <td>0.960647</td>\n",
              "      <td>0.949153</td>\n",
              "      <td>0.511634</td>\n",
              "      <td>0.974245</td>\n",
              "      <td>0.353050</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.594180</td>\n",
              "      <td>0.305708</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.552909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Senior .NET Developer Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.075829</td>\n",
              "      <td>0.140969</td>\n",
              "      <td>0.219446</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.468451</td>\n",
              "      <td>0.130797</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.361658</td>\n",
              "      <td>...</td>\n",
              "      <td>0.965152</td>\n",
              "      <td>0.949896</td>\n",
              "      <td>0.633955</td>\n",
              "      <td>0.974626</td>\n",
              "      <td>0.275643</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.525017</td>\n",
              "      <td>0.365125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.604256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Senior Electrical Engineer Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.061224</td>\n",
              "      <td>0.115385</td>\n",
              "      <td>0.089996</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.299994</td>\n",
              "      <td>0.051181</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.226232</td>\n",
              "      <td>...</td>\n",
              "      <td>0.929579</td>\n",
              "      <td>0.870798</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.933166</td>\n",
              "      <td>0.345098</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.587450</td>\n",
              "      <td>0.417491</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.646135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Senior Electrical Engineer Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.073840</td>\n",
              "      <td>0.137525</td>\n",
              "      <td>0.193880</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.440318</td>\n",
              "      <td>0.113323</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.336634</td>\n",
              "      <td>...</td>\n",
              "      <td>0.933767</td>\n",
              "      <td>0.867550</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.931424</td>\n",
              "      <td>0.301930</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.549482</td>\n",
              "      <td>0.427442</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.653790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Senior Software Engineer Male.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.073113</td>\n",
              "      <td>0.136264</td>\n",
              "      <td>0.155313</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.394097</td>\n",
              "      <td>0.091555</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.302581</td>\n",
              "      <td>...</td>\n",
              "      <td>0.938588</td>\n",
              "      <td>0.935043</td>\n",
              "      <td>0.765121</td>\n",
              "      <td>0.966976</td>\n",
              "      <td>0.349668</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.591327</td>\n",
              "      <td>0.322425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.567825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Senior Software Engineer Male.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.101737</td>\n",
              "      <td>0.184685</td>\n",
              "      <td>0.254636</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.504615</td>\n",
              "      <td>0.158573</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.398212</td>\n",
              "      <td>...</td>\n",
              "      <td>0.946335</td>\n",
              "      <td>0.935243</td>\n",
              "      <td>0.822508</td>\n",
              "      <td>0.967079</td>\n",
              "      <td>0.286817</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.535553</td>\n",
              "      <td>0.391017</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.625313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Trainee UX-UI Designer Female.pdf</td>\n",
              "      <td>Business Analyst.txt</td>\n",
              "      <td>0.021341</td>\n",
              "      <td>0.041791</td>\n",
              "      <td>0.123320</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.351169</td>\n",
              "      <td>0.068277</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.261299</td>\n",
              "      <td>...</td>\n",
              "      <td>0.872746</td>\n",
              "      <td>0.857920</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.926240</td>\n",
              "      <td>0.303523</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.550929</td>\n",
              "      <td>0.118405</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.344100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Trainee UX-UI Designer Female.pdf</td>\n",
              "      <td>Senior Software Developer.txt</td>\n",
              "      <td>0.035144</td>\n",
              "      <td>0.067901</td>\n",
              "      <td>0.176804</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.420481</td>\n",
              "      <td>0.101756</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.318992</td>\n",
              "      <td>...</td>\n",
              "      <td>0.883191</td>\n",
              "      <td>0.865122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.930119</td>\n",
              "      <td>0.258879</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.508802</td>\n",
              "      <td>0.164603</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.405713</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>24 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Resume                       Position  \\\n",
              "0                Business analyst Male.pdf           Business Analyst.txt   \n",
              "1                Business analyst Male.pdf  Senior Software Developer.txt   \n",
              "2       Junior Frontend Developer Male.pdf           Business Analyst.txt   \n",
              "3       Junior Frontend Developer Male.pdf  Senior Software Developer.txt   \n",
              "4   Junior Full Stack Developer Female.pdf           Business Analyst.txt   \n",
              "5   Junior Full Stack Developer Female.pdf  Senior Software Developer.txt   \n",
              "6     Junior Software Developer Female.pdf           Business Analyst.txt   \n",
              "7     Junior Software Developer Female.pdf  Senior Software Developer.txt   \n",
              "8           Middle .NET Developer Male.pdf           Business Analyst.txt   \n",
              "9           Middle .NET Developer Male.pdf  Senior Software Developer.txt   \n",
              "10           Middle Java Engineer Male.pdf           Business Analyst.txt   \n",
              "11           Middle Java Engineer Male.pdf  Senior Software Developer.txt   \n",
              "12    Product Marketing Manager Female.pdf           Business Analyst.txt   \n",
              "13    Product Marketing Manager Female.pdf  Senior Software Developer.txt   \n",
              "14                QA Specialist Female.pdf           Business Analyst.txt   \n",
              "15                QA Specialist Female.pdf  Senior Software Developer.txt   \n",
              "16          Senior .NET Developer Male.pdf           Business Analyst.txt   \n",
              "17          Senior .NET Developer Male.pdf  Senior Software Developer.txt   \n",
              "18     Senior Electrical Engineer Male.pdf           Business Analyst.txt   \n",
              "19     Senior Electrical Engineer Male.pdf  Senior Software Developer.txt   \n",
              "20       Senior Software Engineer Male.pdf           Business Analyst.txt   \n",
              "21       Senior Software Engineer Male.pdf  Senior Software Developer.txt   \n",
              "22       Trainee UX-UI Designer Female.pdf           Business Analyst.txt   \n",
              "23       Trainee UX-UI Designer Female.pdf  Senior Software Developer.txt   \n",
              "\n",
              "    Jaccard similarity  Dice similarity  Bag-of-words cosine similarity  \\\n",
              "0             0.065817         0.123506                        0.183584   \n",
              "1             0.065076         0.122200                        0.128332   \n",
              "2             0.056604         0.107143                        0.116304   \n",
              "3             0.076419         0.141988                        0.175285   \n",
              "4             0.039583         0.076152                        0.109768   \n",
              "5             0.070175         0.131148                        0.205910   \n",
              "6             0.043590         0.083538                        0.133633   \n",
              "7             0.070270         0.131313                        0.155096   \n",
              "8             0.002933         0.005848                        0.000000   \n",
              "9             0.003030         0.006042                        0.000000   \n",
              "10            0.051220         0.097448                        0.113253   \n",
              "11            0.063291         0.119048                        0.163574   \n",
              "12            0.053435         0.101449                        0.098227   \n",
              "13            0.052219         0.099256                        0.109836   \n",
              "14            0.036876         0.071130                        0.071194   \n",
              "15            0.066210         0.124197                        0.160537   \n",
              "16            0.044944         0.086022                        0.137344   \n",
              "17            0.075829         0.140969                        0.219446   \n",
              "18            0.061224         0.115385                        0.089996   \n",
              "19            0.073840         0.137525                        0.193880   \n",
              "20            0.073113         0.136264                        0.155313   \n",
              "21            0.101737         0.184685                        0.254636   \n",
              "22            0.021341         0.041791                        0.123320   \n",
              "23            0.035144         0.067901                        0.176804   \n",
              "\n",
              "    Bag-of-words sqrt-cos similarity  \\\n",
              "0                                NaN   \n",
              "1                                NaN   \n",
              "2                                NaN   \n",
              "3                                NaN   \n",
              "4                                NaN   \n",
              "5                                NaN   \n",
              "6                                NaN   \n",
              "7                                NaN   \n",
              "8                                NaN   \n",
              "9                                NaN   \n",
              "10                               NaN   \n",
              "11                               NaN   \n",
              "12                               NaN   \n",
              "13                               NaN   \n",
              "14                               NaN   \n",
              "15                               NaN   \n",
              "16                               NaN   \n",
              "17                               NaN   \n",
              "18                               NaN   \n",
              "19                               NaN   \n",
              "20                               NaN   \n",
              "21                               NaN   \n",
              "22                               NaN   \n",
              "23                               NaN   \n",
              "\n",
              "    Bag-of-words improved sqrt-cos similarity  Tf-idf cosine similarity  \\\n",
              "0                                    0.428467                  0.111082   \n",
              "1                                    0.358235                  0.074858   \n",
              "2                                    0.341034                  0.064117   \n",
              "3                                    0.418670                  0.104283   \n",
              "4                                    0.331313                  0.060767   \n",
              "5                                    0.453773                  0.120432   \n",
              "6                                    0.365558                  0.077524   \n",
              "7                                    0.393823                  0.090537   \n",
              "8                                    0.000000                  0.000000   \n",
              "9                                    0.000000                  0.000000   \n",
              "10                                   0.336531                  0.064098   \n",
              "11                                   0.404443                  0.096554   \n",
              "12                                   0.313411                  0.054239   \n",
              "13                                   0.331415                  0.060995   \n",
              "14                                   0.266823                  0.038044   \n",
              "15                                   0.400671                  0.094412   \n",
              "16                                   0.370599                  0.077546   \n",
              "17                                   0.468451                  0.130797   \n",
              "18                                   0.299994                  0.051181   \n",
              "19                                   0.440318                  0.113323   \n",
              "20                                   0.394097                  0.091555   \n",
              "21                                   0.504615                  0.158573   \n",
              "22                                   0.351169                  0.068277   \n",
              "23                                   0.420481                  0.101756   \n",
              "\n",
              "    Tf-idf sqrt-cos similarity  Tf-idf improved sqrt-cos similarity  ...  \\\n",
              "0                          NaN                             0.333289  ...   \n",
              "1                          NaN                             0.273601  ...   \n",
              "2                          NaN                             0.253213  ...   \n",
              "3                          NaN                             0.322929  ...   \n",
              "4                          NaN                             0.246509  ...   \n",
              "5                          NaN                             0.347033  ...   \n",
              "6                          NaN                             0.278431  ...   \n",
              "7                          NaN                             0.300893  ...   \n",
              "8                          NaN                             0.000000  ...   \n",
              "9                          NaN                             0.000000  ...   \n",
              "10                         NaN                             0.253175  ...   \n",
              "11                         NaN                             0.310731  ...   \n",
              "12                         NaN                             0.232892  ...   \n",
              "13                         NaN                             0.246973  ...   \n",
              "14                         NaN                             0.195049  ...   \n",
              "15                         NaN                             0.307265  ...   \n",
              "16                         NaN                             0.278472  ...   \n",
              "17                         NaN                             0.361658  ...   \n",
              "18                         NaN                             0.226232  ...   \n",
              "19                         NaN                             0.336634  ...   \n",
              "20                         NaN                             0.302581  ...   \n",
              "21                         NaN                             0.398212  ...   \n",
              "22                         NaN                             0.261299  ...   \n",
              "23                         NaN                             0.318992  ...   \n",
              "\n",
              "    GloVe improved sqrt-cos similarity  FastText cosine similarity  \\\n",
              "0                             0.963443                    0.959791   \n",
              "1                             0.960415                    0.957273   \n",
              "2                             0.962810                    0.971515   \n",
              "3                             0.967528                    0.974688   \n",
              "4                             0.950115                    0.890547   \n",
              "5                             0.954712                    0.894368   \n",
              "6                             0.895564                    0.863143   \n",
              "7                             0.887932                    0.860557   \n",
              "8                             0.537811                   -0.113323   \n",
              "9                             0.548054                   -0.106376   \n",
              "10                            0.940232                    0.907037   \n",
              "11                            0.945075                    0.906687   \n",
              "12                            0.910575                    0.923270   \n",
              "13                            0.895229                    0.914873   \n",
              "14                            0.942004                    0.856409   \n",
              "15                            0.945719                    0.857602   \n",
              "16                            0.960647                    0.949153   \n",
              "17                            0.965152                    0.949896   \n",
              "18                            0.929579                    0.870798   \n",
              "19                            0.933767                    0.867550   \n",
              "20                            0.938588                    0.935043   \n",
              "21                            0.946335                    0.935243   \n",
              "22                            0.872746                    0.857920   \n",
              "23                            0.883191                    0.865122   \n",
              "\n",
              "    FastText sqrt-cos similarity  FastText improved sqrt-cos similarity  \\\n",
              "0                       0.920888                               0.979689   \n",
              "1                       0.940580                               0.978403   \n",
              "2                       0.917988                               0.985655   \n",
              "3                       0.947980                               0.987263   \n",
              "4                            NaN                               0.943688   \n",
              "5                            NaN                               0.945710   \n",
              "6                            NaN                               0.929055   \n",
              "7                            NaN                               0.927662   \n",
              "8                            NaN                                    NaN   \n",
              "9                            NaN                                    NaN   \n",
              "10                           NaN                               0.952385   \n",
              "11                           NaN                               0.952201   \n",
              "12                      0.922753                               0.960869   \n",
              "13                      0.909760                               0.956490   \n",
              "14                           NaN                               0.925423   \n",
              "15                           NaN                               0.926068   \n",
              "16                      0.511634                               0.974245   \n",
              "17                      0.633955                               0.974626   \n",
              "18                           NaN                               0.933166   \n",
              "19                           NaN                               0.931424   \n",
              "20                      0.765121                               0.966976   \n",
              "21                      0.822508                               0.967079   \n",
              "22                           NaN                               0.926240   \n",
              "23                           NaN                               0.930119   \n",
              "\n",
              "    BERT cosine tensor similarity  BERT sqrt-cos tensor similarity  \\\n",
              "0                        0.388061                              NaN   \n",
              "1                        0.313262                              NaN   \n",
              "2                        0.339251                              NaN   \n",
              "3                        0.303084                              NaN   \n",
              "4                        0.360206                              NaN   \n",
              "5                        0.301823                              NaN   \n",
              "6                        0.246990                              NaN   \n",
              "7                        0.329097                              NaN   \n",
              "8                        0.286953                              NaN   \n",
              "9                        0.282867                              NaN   \n",
              "10                       0.313322                              NaN   \n",
              "11                       0.265086                              NaN   \n",
              "12                       0.334942                              NaN   \n",
              "13                       0.284834                              NaN   \n",
              "14                       0.375284                              NaN   \n",
              "15                       0.286374                              NaN   \n",
              "16                       0.353050                              NaN   \n",
              "17                       0.275643                              NaN   \n",
              "18                       0.345098                              NaN   \n",
              "19                       0.301930                              NaN   \n",
              "20                       0.349668                              NaN   \n",
              "21                       0.286817                              NaN   \n",
              "22                       0.303523                              NaN   \n",
              "23                       0.258879                              NaN   \n",
              "\n",
              "    BERT improved sqrt-cos tensor similarity  ElMo cosine tensor similarity  \\\n",
              "0                                   0.622945                       0.429953   \n",
              "1                                   0.559698                       0.449745   \n",
              "2                                   0.582453                       0.366787   \n",
              "3                                   0.550531                       0.406456   \n",
              "4                                   0.600171                       0.367743   \n",
              "5                                   0.549384                       0.416390   \n",
              "6                                   0.496980                       0.229923   \n",
              "7                                   0.573670                       0.289976   \n",
              "8                                   0.535680                       0.109714   \n",
              "9                                   0.531853                       0.141840   \n",
              "10                                  0.559751                       0.276039   \n",
              "11                                  0.514865                       0.349242   \n",
              "12                                  0.578741                       0.348699   \n",
              "13                                  0.533698                       0.380822   \n",
              "14                                  0.612604                       0.334746   \n",
              "15                                  0.535139                       0.388531   \n",
              "16                                  0.594180                       0.305708   \n",
              "17                                  0.525017                       0.365125   \n",
              "18                                  0.587450                       0.417491   \n",
              "19                                  0.549482                       0.427442   \n",
              "20                                  0.591327                       0.322425   \n",
              "21                                  0.535553                       0.391017   \n",
              "22                                  0.550929                       0.118405   \n",
              "23                                  0.508802                       0.164603   \n",
              "\n",
              "    ElMo sqrt-cos tensor similarity  ElMo improved sqrt-cos tensor similarity  \n",
              "0                               NaN                                  0.655708  \n",
              "1                               NaN                                  0.670631  \n",
              "2                               NaN                                  0.605629  \n",
              "3                               NaN                                  0.637539  \n",
              "4                               NaN                                  0.606418  \n",
              "5                               NaN                                  0.645283  \n",
              "6                               NaN                                  0.479502  \n",
              "7                               NaN                                  0.538494  \n",
              "8                               NaN                                  0.331231  \n",
              "9                               NaN                                  0.376617  \n",
              "10                              NaN                                  0.525394  \n",
              "11                              NaN                                  0.590967  \n",
              "12                              NaN                                  0.590508  \n",
              "13                              NaN                                  0.617108  \n",
              "14                              NaN                                  0.578573  \n",
              "15                              NaN                                  0.623323  \n",
              "16                              NaN                                  0.552909  \n",
              "17                              NaN                                  0.604256  \n",
              "18                              NaN                                  0.646135  \n",
              "19                              NaN                                  0.653790  \n",
              "20                              NaN                                  0.567825  \n",
              "21                              NaN                                  0.625313  \n",
              "22                              NaN                                  0.344100  \n",
              "23                              NaN                                  0.405713  \n",
              "\n",
              "[24 rows x 25 columns]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRTbGPPibR8O"
      },
      "source": [
        "Next, ideal candidates' ranking is defined by the expert, where 1 marks the most suitable candidate, 12 marks the least suitable candidate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncfZK-2ubR8O"
      },
      "source": [
        "Business Analyst, Amazon:\n",
        "- 1 - Business analyst Male.pdf\n",
        "- 7 - Junior Frontend Developer Male.pdf\n",
        "- 3 - Junior Full Stack Developer Female.pdf\n",
        "- 12 - Junior Software Developer Female.pdf\n",
        "- 10 - Middle .NET Developer Male.pdf\n",
        "- 9 - Middle Java Engineer Male.pdf\n",
        "- 5 - Product Marketing Manager Female.pdf\n",
        "- 6 - QA Specialist Female.pdf\n",
        "- 4 - Senior .NET Developer Male.pdf\n",
        "- 8 - Senior Electrical Engineer Male.pdf\n",
        "- 3 - Senior Software Engineer Male.pdf\n",
        "- 12 - Trainee UX-UI Designer Female.pdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKh7eodBbR8O"
      },
      "source": [
        "Senior Software Engineer, Google:\n",
        "- 7 - Business analyst Male.pdf\n",
        "- 8 - Junior Frontend Developer Male.pdf\n",
        "- 5 - Junior Full Stack Developer Female.pdf\n",
        "- 10 - Junior Software Developer Female.pdf\n",
        "- 2 - Middle .NET Developer Male.pdf\n",
        "- 7 - Middle Java Engineer Male.pdf\n",
        "- 8 - Product Marketing Manager Female.pdf\n",
        "- 3 - QA Specialist Female.pdf\n",
        "- 3 - Senior .NET Developer Male.pdf\n",
        "- 9 - Senior Electrical Engineer Male.pdf\n",
        "- 1 - Senior Software Engineer Male.pdf\n",
        "- 12 - Trainee UX-UI Designer Female.pdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euXCZnx2bR8O"
      },
      "outputs": [],
      "source": [
        "# Define lists of expert rankings\n",
        "ba_ideal_rank = pd.Series([1, 7, 3, 12, 10, 9, 5, 3, 4, 8, 3, 11], name=\"Business Analyst profession ranking\").astype(dtype=np.float64)\n",
        "se_ideal_rank = pd.Series([7, 8, 5, 10, 2, 7, 8, 3, 3, 9, 1, 12], name=\"Senior Software Engineer profession ranking\").astype(dtype=np.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtlrZiYkbR8O",
        "outputId": "dcec0a5f-3519-413f-9cef-c15474782a9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weighted Tau coefficient for BERT cosine tensor similarity equals 0.8674191741179471\n",
            "Weighted Tau coefficient for BERT improved sqrt-cos tensor similarity equals 0.8674191741179471\n",
            "Weighted Tau coefficient for Word2Vec cosine similarity equals 0.5801721967564071\n",
            "Weighted Tau coefficient for Word2Vec improved sqrt-cos similarity equals 0.5801721967564071\n",
            "Weighted Tau coefficient for GloVe cosine similarity equals 0.5643702849778357\n",
            "Weighted Tau coefficient for GloVe improved sqrt-cos similarity equals 0.5643702849778357\n",
            "Weighted Tau coefficient for ElMo cosine tensor similarity equals 0.5592359727945382\n",
            "Weighted Tau coefficient for ElMo improved sqrt-cos tensor similarity equals 0.5592359727945382\n",
            "Weighted Tau coefficient for FastText cosine similarity equals 0.38780912975348425\n",
            "Weighted Tau coefficient for Jaccard similarity equals 0.339690242290892\n",
            "Weighted Tau coefficient for Dice similarity equals 0.339690242290892\n",
            "Weighted Tau coefficient for GloVe sqrt-cos similarity equals 0.2326583048121824\n",
            "Weighted Tau coefficient for FastText improved sqrt-cos similarity equals 0.1644450799144757\n",
            "Weighted Tau coefficient for Bag-of-words cosine similarity equals 0.06397369357108959\n",
            "Weighted Tau coefficient for Bag-of-words improved sqrt-cos similarity equals 0.06397369357108959\n",
            "Weighted Tau coefficient for Tf-idf cosine similarity equals 0.06397369357108959\n",
            "Weighted Tau coefficient for Tf-idf improved sqrt-cos similarity equals 0.06397369357108959\n",
            "Weighted Tau coefficient for Word2Vec sqrt-cos similarity equals -0.31141906007369613\n",
            "Weighted Tau coefficient for FastText sqrt-cos similarity equals -0.45518117755954546\n",
            "Weighted Tau coefficient for Bag-of-words sqrt-cos similarity equals -0.483619504543505\n",
            "Weighted Tau coefficient for Tf-idf sqrt-cos similarity equals -0.483619504543505\n",
            "Weighted Tau coefficient for BERT sqrt-cos tensor similarity equals -0.483619504543505\n",
            "Weighted Tau coefficient for ElMo sqrt-cos tensor similarity equals -0.483619504543505\n"
          ]
        }
      ],
      "source": [
        "# Calculate Kendall's Tau weighted coefficients for every metrics and model - Business Analyst Amazon\n",
        "weightedtau_coefficients = {}\n",
        "for coefficient in df[df['Position'] == 'Business Analyst.txt'].columns[2:]:\n",
        "    weightedtau_coefficients[coefficient] = stats.weightedtau(df[df['Position'] == 'Business Analyst.txt'][coefficient].rank(ascending=False), ba_ideal_rank)[0]\n",
        "sorted_weightedtau_coefficients = sorted(weightedtau_coefficients.items(), key=lambda x: (np.isnan(x[1]), -x[1] if not np.isnan(x[1]) else np.inf))\n",
        "for coefficient, value in sorted_weightedtau_coefficients:\n",
        "    if np.isnan(value):\n",
        "        print(f\"Weighted Tau coefficient for {coefficient} equals NaN\")\n",
        "    else:\n",
        "        print(f\"Weighted Tau coefficient for {coefficient} equals {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXEyWe_ZbR8P",
        "outputId": "b406031f-804a-4a86-b1eb-84983e8579c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Weighted Tau coefficient for GloVe sqrt-cos similarity equals 0.8276414238016554\n",
            "Weighted Tau coefficient for GloVe cosine similarity equals 0.31069970138022807\n",
            "Weighted Tau coefficient for GloVe improved sqrt-cos similarity equals 0.31069970138022807\n",
            "Weighted Tau coefficient for FastText improved sqrt-cos similarity equals 0.2969169791042248\n",
            "Weighted Tau coefficient for Word2Vec cosine similarity equals 0.2399238308633545\n",
            "Weighted Tau coefficient for Word2Vec improved sqrt-cos similarity equals 0.2399238308633545\n",
            "Weighted Tau coefficient for BERT cosine tensor similarity equals 0.16012410391050208\n",
            "Weighted Tau coefficient for BERT improved sqrt-cos tensor similarity equals 0.16012410391050208\n",
            "Weighted Tau coefficient for ElMo cosine tensor similarity equals 0.14686813039501512\n",
            "Weighted Tau coefficient for ElMo improved sqrt-cos tensor similarity equals 0.14686813039501512\n",
            "Weighted Tau coefficient for Jaccard similarity equals 0.13644042210955845\n",
            "Weighted Tau coefficient for Dice similarity equals 0.13644042210955845\n",
            "Weighted Tau coefficient for FastText cosine similarity equals -0.004999068814471527\n",
            "Weighted Tau coefficient for Tf-idf cosine similarity equals -0.050225202732833485\n",
            "Weighted Tau coefficient for Tf-idf improved sqrt-cos similarity equals -0.050225202732833485\n",
            "Weighted Tau coefficient for Bag-of-words sqrt-cos similarity equals -0.0932795010340347\n",
            "Weighted Tau coefficient for Tf-idf sqrt-cos similarity equals -0.0932795010340347\n",
            "Weighted Tau coefficient for BERT sqrt-cos tensor similarity equals -0.0932795010340347\n",
            "Weighted Tau coefficient for ElMo sqrt-cos tensor similarity equals -0.0932795010340347\n",
            "Weighted Tau coefficient for Bag-of-words cosine similarity equals -0.09366269901859926\n",
            "Weighted Tau coefficient for Bag-of-words improved sqrt-cos similarity equals -0.09366269901859926\n",
            "Weighted Tau coefficient for Word2Vec sqrt-cos similarity equals -0.40203167532913964\n",
            "Weighted Tau coefficient for FastText sqrt-cos similarity equals -0.4188873196519247\n"
          ]
        }
      ],
      "source": [
        "# Calculate Kendall's Tau weighted coefficients for every metrics and model - Senior Software Engineer Google\n",
        "weightedtau_coefficients = {}\n",
        "for coefficient in df[df['Position'] == 'Senior Software Developer.txt'].columns[2:]:\n",
        "    weightedtau_coefficients[coefficient] = stats.weightedtau(df[df['Position'] == 'Senior Software Developer.txt'][coefficient].rank(ascending=False), se_ideal_rank)[0]\n",
        "sorted_weightedtau_coefficients = sorted(weightedtau_coefficients.items(), key=lambda x: (np.isnan(x[1]), -x[1] if not np.isnan(x[1]) else np.inf))\n",
        "for coefficient, value in sorted_weightedtau_coefficients:\n",
        "    if np.isnan(value):\n",
        "        print(f\"Weighted Tau coefficient for {coefficient} equals NaN\")\n",
        "    else:\n",
        "        print(f\"Weighted Tau coefficient for {coefficient} equals {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_qxgORwbR8P"
      },
      "source": [
        "### Section 4. Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtbzMoUgbR8P"
      },
      "source": [
        "To compare human and algorithmic efficiency and understand their correlation, a manual ranking was conducted. This involved manual evaluation for assessing and ranking candidates’ skills based on their resumes. These manual rankings were then compared to the rankings generated by the intelligent system. The comparison aimed to identify discrepancies, validate the effectiveness of the automated system, and determine the extent to which human judgment aligns with algorithmic assessments.\n",
        "\n",
        "The results obtained show a significant improvement in assesing candidates’ skills, achieving a Weighted Tau coefficient of up to 0.857, though the initial data must be taken into account. My recommendations also include the active involvement of a hybrid “Human-in-the-loop” approach to ensure the optimal combination of intelligent\n",
        "technologies and peer review, thereby ensuring objectivity and neutrality in the process of assessing candidate skills."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}